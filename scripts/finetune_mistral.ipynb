{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e800f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs: 2\n",
      "GPU 0: NVIDIA GeForce RTX 5090\n",
      "Memory: 33.7 GB\n",
      "GPU 1: NVIDIA GeForce RTX 3090 Ti\n",
      "Memory: 25.3 GB\n",
      "Dataset size: 9523 samples\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tune Llama for Antibody Sequence Generation\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Setup environment\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test GPU setup\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/sabdab/sabdab_training_dataset.csv\")\n",
    "df = df.dropna(subset=['h_chain_seq', 'l_chain_seq', 'antigen_seqs', 'highlighted_epitope_seqs'])\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3668bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mistralai/Mistral-7B-Instruct-v0.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Choose Llama model - you can use different versions\n",
    " \n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\" #\"meta-llama/Llama-3.1-8b-instruct\"  # Change this to your preferred Llama model\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "# Set padding token if not present (common for Llama models)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load model with automatic device mapping for multi-GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Automatically distribute across GPUs\n",
    "    torch_dtype=torch.float16,  # Use float16 for efficiency\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    max_memory={0: \"30GB\", 1: \"23GB\"}  # Adjust based on your GPU memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b944a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens for epitopes\n",
    "epitope_tokens = [\"<epi>\", \"</epi>\"]\n",
    "task_tokens = [\"Antigen\", \"Antibody\", \"Epitope\"]\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "extra_tokens = amino_acids + [\"|\"]\n",
    "\n",
    "# Add all custom tokens\n",
    "all_new_tokens = epitope_tokens + task_tokens + [t for t in extra_tokens if t not in tokenizer.get_vocab()]\n",
    "num_added_tokens = tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": tokenizer.additional_special_tokens + all_new_tokens\n",
    "    if tokenizer.additional_special_tokens else all_new_tokens\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcb8d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 new tokens to vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Resize model embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Added {num_added_tokens} new tokens to vocabulary\")\n",
    "\n",
    "# Prepare dataset\n",
    "def convert_epitope_format(sequence):\n",
    "    \"\"\"Convert [X] format to <epi>X</epi> format\"\"\"\n",
    "    return re.sub(r'\\[([A-Z])\\]', r'<epi>\\\\1</epi>', sequence)\n",
    "\n",
    "def format_prompt(example):\n",
    "    epitope_seq = convert_epitope_format(example['highlighted_epitope_seqs'])\n",
    "    # Using Llama's typical prompt format\n",
    "    return {\n",
    "        \"text\": f\"### Instruction: Generate antibody sequence for the given antigen.\\n\\n### Input:\\nAntigen: {epitope_seq}\\n\\n### Response:\\nAntibody: {example['antibody_fv_seqs']}\\n\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9d50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9523/9523 [00:00<00:00, 18642.84 examples/s]\n",
      "Map: 100%|██████████| 9523/9523 [00:02<00:00, 3467.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences truncated at max_length=1024: 92/9523 (1.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create and map dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(format_prompt)\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize(example):\n",
    "    # Llama models typically have longer context windows (4096 tokens)\n",
    "    encoded = tokenizer(\n",
    "        example[\"text\"], \n",
    "        truncation=True, \n",
    "        max_length=1024,  # Adjust based on your sequences\n",
    "        padding=False\n",
    "    )\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    return encoded\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n",
    "\n",
    "# Check sequence lengths\n",
    "sequence_lengths = [len(tokenizer(example[\"text\"], truncation=False)[\"input_ids\"]) for example in dataset]\n",
    "max_len = 1024\n",
    "truncated = sum(1 for length in sequence_lengths if length > max_len)\n",
    "print(f\"Sequences truncated at max_length={max_len}: {truncated}/{len(sequence_lengths)} ({100*truncated/len(sequence_lengths):.1f}%)\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_remove = [col for col in tokenized_dataset.column_names if col not in [\"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12516b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,255,404,544 || trainable%: 0.1879\n"
     ]
    }
   ],
   "source": [
    "# Enable gradient computation for inputs\n",
    "if hasattr(model, 'enable_input_require_grads'):\n",
    "    model.enable_input_require_grads()\n",
    "else:\n",
    "    def make_inputs_require_grad(module, input, output):\n",
    "        output.requires_grad_(True)\n",
    "    model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)\n",
    "\n",
    "# Configure LoRA for efficient fine-tuning\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Llama attention modules\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb308283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments optimized for Llama\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/llama-antibody-{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "    per_device_train_batch_size=4,  # Adjust based on GPU memory\n",
    "    gradient_accumulation_steps=2,  # Effective batch size = 8\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=5e-5,  # Conservative learning rate for Llama\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    eval_strategy=\"no\",  # Add validation set if needed\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"none\",  # Change to \"wandb\" for logging\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b85690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Generation Callback\n",
    "class TestGenerationCallback(TrainerCallback):\n",
    "    def __init__(self, model, tokenizer, test_antigens, log_every_n_steps=100):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_antigens = test_antigens\n",
    "        self.log_every_n_steps = log_every_n_steps\n",
    "        \n",
    "    def create_test_prompt(self, antigen_with_epitopes):\n",
    "        return f\"### Instruction: Generate antibody sequence for the given antigen.\\n\\n### Input:\\nAntigen: {antigen_with_epitopes}\\n\\n### Response:\\nAntibody:\"\n",
    "    \n",
    "    def generate_antibody_test(self, antigen_with_epitopes):\n",
    "        prompt = self.create_test_prompt(antigen_with_epitopes)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        self.model.eval()\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=200,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                    repetition_penalty=1.1,\n",
    "                )\n",
    "                \n",
    "                generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "                if \"Antibody:\" in generated_text:\n",
    "                    antibody_part = generated_text.split(\"Antibody:\", 1)[1]\n",
    "                    antibody_sequence = antibody_part.split(\"\\n\")[0].strip()\n",
    "                else:\n",
    "                    antibody_sequence = \"Generation failed\"\n",
    "                \n",
    "                return antibody_sequence\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "        finally:\n",
    "            self.model.train()\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        if state.global_step % self.log_every_n_steps == 0 and state.global_step > 0:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"TEST GENERATION - Step {state.global_step}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            for i, test_antigen in enumerate(self.test_antigens):\n",
    "                antibody = self.generate_antibody_test(test_antigen)\n",
    "                print(f\"\\n--- Test Case {i+1} ---\")\n",
    "                print(f\"Input: {test_antigen[:60]}...\")\n",
    "                print(f\"Generated: {antibody}\")\n",
    "            \n",
    "            print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ba53f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|██████████| 9523/9523 [00:00<00:00, 190865.18 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Create test antigens\n",
    "test_antigens = [\n",
    "    convert_epitope_format(\"KVFGRCELAAAM[K][R]HGL[D][N][Y]RG[Y][S]LG[N]WVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCA[K]KIVSDGNGMNAWVAWRNRCK[G][T][D]V[Q]AW[I][R]GCRL\"),\n",
    "    convert_epitope_format(\"NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI[R]G[N]EV[S][Q]IAPGQ[T]GNIADYNYKLPDDFTGCVIAWNSN[K]LDSKPSGNYNYLYRLLRKSKLKPFERDISTEIYQAGNKPCNGVAGPNCYSPLQSYGF[R]P[T][Y][G][V]GH[Q]PYRVVVLSFELLHAPATVCGP\"),\n",
    "]\n",
    "\n",
    "# Initialize callback\n",
    "test_callback = TestGenerationCallback(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    test_antigens=test_antigens,\n",
    "    log_every_n_steps=100\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    callbacks=[test_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee0b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3573' max='3573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3573/3573 3:19:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.445100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.401500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.922300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.856900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.889800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.853200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.835900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.877300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.861200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.779300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.861500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.853300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.746500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.714300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>1.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.710200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>1.584400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>1.797200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 100\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGGGVLVQPGGSLTCTAYSISHWVRQSPGSKLEWIGEYYMVDTYAGNSSSGDPSGTSVTVSS|DISSLTQMTITPSEGSLKSYMSNGAWYQQQLQRPGKSAWYQQGYLTVSSVADSLGPEAATLTISSKNSENLSLTFDDTAVYYCQQSYSNNYLKMNNIYSSEDLAWYQGQTTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFSFISSYYHWVRQAPGKGLEWVASITGSDTPKFRADSEVTISRDNAKFKKATAYLQMNLQDVVYACMEWYGRGTSVTVSS|DIVLTQSPSSVSATSGVRTISCTSGTDYLAWYQQKPWYQQGKAPKLLIYSQSNSTVGSGERSDASLTISRAELQADYFCQQYYCQQYLQMNSLQTSEDTAVYYCQQSGAETVVK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 200\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVQSGAELKPGASVKLSCKASGYTFTSYWMHWVRQAPGQGLEWIGEIYNPSNKYYADSVKGRFTISRDNSKNTLYLQMSSLRSEDTAVYYCTRNYGSGTFDYWGQGTLVTVSA|DIVLTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGQSPRLLIYKASTRATGIPARFSGSGSGTDFTLTITSLQPEDEAYYCQQYNNPWTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLLESGGGLLSCAASGFTISCTGSGTSYSSYWMHWVKQRPGQGLEWIGMIYYGTSNNYAQKFKATLTADKSSSKTMTVSSLTSEDSAVYYCARRHSLYMWGRGTLVTV|DIVLTQSPSSLSASVGDRVTITCRASQDISAWYQQKPGKAPKLLIYNASTSRPSGIPARFSGSGSGTDFTLTISSLQAEDVAVYYCQQHNWFLTVG\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 300\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGAEVKKPGSSVKVSCKASGFNIYGSDRYYWIRQSPSGKGLEWIGEIIPDNNYAGSVEGRFTISRDSALTNSLKLTMEDLRAIYYCTRGGVVFDYWGQGTTLTVSS|DIVLTQSPATLSVTPGQRVTISCSGDNGSIHWYQQKPGQAPLLLIYAASNLQSGVPSRFSGSGSGTSYSLTISSMEAEDAATYYCQQSLLRPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QSGLKQSGPELVQPGGSLRLSCARDSGDFTDYWSHWVRQPPGKGLEWIGIIYPSEGTTYYNTQFKGRVTITRDSSCTALGWFLQLTSVDTEDTAMYYCARPVYGFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGETVTITCRASQGISSNYLAWYQQKPGKAPKLLLIYAASNLQSGVPSRFSGSGSGTDFTLTINLAIHTQEDDAATYYCQQSYSIPTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 400\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQSGAELVRPGASVKLSCKASGYTFTSYAISWVRQAPGKGLEWIGIIYSTSGSTYYADSVKGRFSISRDNSKNTLYLQMNSLRSEDTAMYYCARRVLGANWFAFWRVTAYWGQGTLVTVS|DIVLTQSPAIMSAKVSGKVTMTCSGSSSNIHWYQQKPEGKSPWTLLSIYDNNKRPSGVPDRFSGSGSGTDYSLTINSTISGLQAEDEADYYCAAWDDSLWLTFGGGTKLTVL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLLESGGGLVQPGGSLRLSCAASGFTFSNYAMSWVRQAPGKGLEWVSAISGGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARSGEVSDDWGQGTTLVT|DIQMTQSPSSMSVSALKTTITCKASQSVSNLAVYYLQKPDHLKPEISGNNKYSRTNRDSGVPDRFSGSGSGTDFTLTISSLQPEDFATYYCQQYGSYTPPYTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 500\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQSGAELVRPGASVKVSCKASGYTFTSYWMHWVKQRPGQGLEWIGEIIPADGTNYAQKFQGRVTMTTDTSTTTGYMELSSLRSEDTAIYYCARPPLYFDYWGQGTLVTVSA|DIVMTQSPSSMSVSLGDTVSITCHASQGISSYLAWYQQKPGKAPKLLISASGSNRFSGVPDRFSGSGSGTDFTLKISRVETEDAATYYCQQYNNWPRTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVKPGGSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVISIDGDHYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDRFGSFYWGQGTLVTVSS|DILLTQSPAIMSVSPGERVTLTCRASENIYVSWLAQQKPGQAPRLLIYGASTRATGVPDRFSGSGSGTDFTLTISSLQSEDFAVYYCQQYNNWLIPFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 600\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQSGAELVRPGASVKLSCTGSGFNIHDDHAYWVKQRPEQGLEWIGEIYYTGDNYTYYADSVKGRFTISRDDASTAYLELSSLRSEDTAVYYCARERGTFYDYWGQGTLVTVSS|DIQMTQSPSSLSASSVEGERLTCRTSQSLSIHSWYQQKAPKLLIYAASESGPSGVSDRFSGSRAGTDFTLTISSLQAEDVAVYYCLQHYGNSPRTFGPGTKVDIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVTLKESGGDLVQPGGSLRLSCAASGFTFSSYYMSWVRQAPGKGLEWIGSIYYSGSTYYNSYADSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCARDRDSSDPWYYYGMDVWGQGTTVTVSS|ELTQPPSVSGSPGQSITISCTGSGDVGKYLAWYQQKPGQAPVLVIYKRDSQRPSGIPDRFSGSNSGNTASLTISGLKTEDEAIYFCSEDDSSLHWVFGGGTKLTVL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 700\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: VQLVESGGGLVKPGGSLRLSCAASGFTFSNYWMHWVRQAPGKGLEWVAVISYDGSNRYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCAKYGDAWNSFFDIWGQGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSALAWYQQKPGKAPKLLIFAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVISYYDGSSSYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCAREGDVSGYYWGQGTTLTV|IVMTQSPATLSLSPGERATLSCRASQSISDSYLAWYQQKPGQAPRLLIYGASTRATGIPARFSGSGSGTEFTLTISSLQSEDFAVYYCQQYNNWPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 800\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQSGPELVKPGETVKISCKTSGYTFTNYWMHWVKQAPGKGLEWIGRIDPSNGDTTYYNQKFKGKATLTVDKSSSTAYMELSSLTSEDSAIYYCVRRGKPYSYYFDYWGQGTTLTVSS|DIVLTQSPSSLAVSLGDQATLSCRASQSVSNNNLAWFQQKPGQPPKLLISAASNLDSGVPDRFSGSGSGTDFTLTISSLQSEDFAVYYCQQYNSWLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQESGPGLVKPSETLSLTCAVSGGSIDSYYYWSWIRQPPGKGLEWIGYIHYPGDTYYNPSLKSRVTMSVDTSKNQFSLKLSSVTAADTAVYYCARDRRGQYFDLWGRGTTLTVSS|QAVVTQESALTTSPGETVTLTCRSSTGAVTTSNYLAWYQQKPGQAPRLLIYGASTRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPRTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 900\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLQESGGGLVQPGGSLRLSCAASGFNVSYYYWHWVRQSPGKGLEWLGIIVPSYTTYADSVKGRFTISRDNSKNTLYLQMRAEDTAIYYCAKDGDLSYYFDYWGQGTTLTV|DIVLTQSPASLAVSLGQRATISCRASQSVDSYGISFMHWYQQKPGQPPKLLISWASTRESGVPDRFIGSGSGTDFALTISRMQAEDAATYYCQQSNYPLTFGAGTKLEL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVQPGGSLRLSCAASEVTVSSNYMSWVRQAPGKGLEWVSILSYGGSITYYADSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCAARAYGTPYDYWGQGTTLTV|SVLTQSPGTLSLSPGERATLSCRASESVDTYSSMNWFQQKPGQPPKLLIYWASTRFSGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCQQYDNSTWTFGQGTKVEI\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1000\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVQSGAEVKKPGASVKLSCTASGFNIKDTYMHWVRQAPGQGLEWMGMIKPIDSGSTYYAQKFQGRVTMTTDTSTTTAYMELRSLRSDDTAVYYCARSPPYDYDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDKVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVQSGAEVKKPGSSVKVSCKASGGTFNNYYIHWVRQAPGQGLEWMGWINNNSGGTANYAQKFQGRVTITADESTTTAYMELSSLRSEDTAVYYCARRGYGDYDYFDYWGQGTTLTVSS|DIVLTQSPASLAVSLGERATINCKSSQSVLNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCQQYYSGPLTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1100\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFNVSYSIHWVRQAPGKGLEWVAYIYYSGGSTYYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARRRGDSGYFAYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQYNNYPLTFGAGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFTFSNYWMHWVRQPPGKGLEWVSGISSGSITYYADSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARGDTVVGAMDYWGQGTLVTVS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKVLIFAASSLQSGVPSRFSGSGSGTDFALTISSLQPEDEADYYCQQYNSYPLTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1200\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQESGPGLVKPSETLSVTCSVSGDSMNNYYWTWIRQSPGKGLEWIGYISDRESANNYNPSLNSRVVSVDTSKNQFSLKLTAADTAVYYCARDRGRGSYDFWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASKQSVSSYLAWYQQKPGKAPKLLIYAASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMHWVRQAPGKGLEWVAYISSSGSTYYADSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCARDRDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTLALTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1300\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVESGGGLVQPGGSLRLSCAASGFNIKKDYMSWVRQAPGKGLEWVSVIYSSSGSTYYADSVKGRFTISADTSKNTAYLQMRAEDTAVYYCARDRPYDDWFDPWGQGTLVTVSS|EIVMTQSPSSLSASVGDRVTITCRASQSISNYLAWYQQKPGKAPKLLIYDASSLYRFSGVPDRFSGSGSGTDFTLTISSLQPEDFATYYCQQYKYPPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFIFSNYYMSWVRQAPGKGLEWVSAISGSGSGTSYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCAREGGGFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQYKYVPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1400\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVIWDGEGSTYYADSVKGRFIISRDNSKNTLYLQMRAEDTAVYYCARERGPYSYDYWGQGTTLTVSS|DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASKLETGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCVTSGITFNTYWMSWVRQAPGKGLEWIGWIYSGDGNTTYYAGSVKGRFTISRDNAKNSLYLQMNNLRAEDTAVYYCARSGAVYYGTIDVWGQGTTVTVSS|IVMTQTPASVSAAPGQTVSITCSGDALAIASYLAWYQQKPDGTPKLLIYGASTRATGVPDRFSGSGSGTDFTLTINNVQSEDLADYFCQQYNNWLPLTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1500\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLQQSGPELVKPGTSVKISCRASGYTFTDYYMYWVKQSHGKSLEWIGEINPVSGSGGTNYNEKFKGKATLTADKSSSTAYMQLSSLTSEDSAIYYCTRQSYSPWFDYWGQGTLVTVSS|DIVMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLLESGGGLVQPGGSLRLSCAASGFTFSNYGMHWVRQTPGKGLEWVSSISSSSYYTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAREIGSGSGYGMDYWGQGTTLTVSS|DIQMTQSPDSLAVSLGERVSMSCKSSQSVLSRNTRAWYQQKPGQPPKLLIYWASTRYSGVPDRFTGSGSGTDFTLTISSVQAEDLAVYYCQQYYSTPLTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1600\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: VQLVQSGAEVKKPGSSVRVSCKAYGVFTNYALPVSWVRQAPGQRLEWMGWISYSGDSDDTKYAQRFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCAREGYGDSYWGQGTLVTVSA|DIVMTQSPLSLSVTPGEPASISCRSSQNGNTYLAWYLHKPGQSPHLLIYWASTRHTGVPDRFSGSGSGTDFTLTISRVETEDLAVYYCQQYNNWLPRTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QSLEESGGDLVKPGASLTLTCTASGDSFISSYAMNWIRQTPGKGLEWIGCIYYSGGTYYNQKFKGRVTITEDTSKSTAYMELTPEDTAVYYCARAEYRGYYGMDVWGQGTTVTV|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCLQHYDNLPLTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1700\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYFMHWVRQAPGKGLEWVAVISYDGSNKYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARERELRGEYFDYWGQGTTVTVSS|DIQLTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPNLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPYTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLQESGGGLVRPGSSSITCSMGFSLGFMNWIGWIWVRQMPGKSLEWIGSIYANNGRYAQKFQGRVTITADKSTTTAYMELTSEDTAVYYCARAVRGDYDWYDYWGQGTTLTVSS|DVLMTQTPSFSVSAVGDRVTITCRASQGISSNLAWYQQKPGKAPNLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCLQHYGSEPLTFGGGTKVEIR\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1800\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVTLKESGPVLVKPTQTLTLTCTFSGFSLSTSGMSGVGWIRQPPGKALEWLADIWDDDKRYNPSLKDRLTISKDTSKNQVVLTMTNMDPVDTATYYCARHYWGQGTLLPWFA|DIQLTQSPSFLSVSPGETITIKCHASQGIDAWAWYQQKPGQSPKLLIYTTSTRLAAGVPDRFTGSGSGTDFTLTISSVQAEDLAVYYCQQYYSYPLTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLQESGGGLVQPGGSLRLSCAASGFIFSRYAMHWVRQAPGKGLEWVAYISSGSGGTYYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARSDYYGSDYWGQGTLVTVSA|DIVLTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCHQYYALPLTFGAGTKLELK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 1900\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QIQLQQSGPELVRPGTSVKMSCKASGYTFTNYWMHWVKQRPGQGLEWIGQIYPGDGDTTYYSQKFKGKATLTADKSSSTAYMQLSSLTSEDSAVYYCARLGFFDYWGQGTTLTV|DIVLTQSPASLAVSLGQRATISCKASQSVDNNYLNWFQQKPGQPPKLLIFETSNRPSGVPDRFSGSGSGTDFTLKISRVEAEDVGIYYCMQGTHFPFTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQESGPGLVKPSGTLSLTCSVTGDSITSGYYWNWIRQPPGRGLEWIGYIYYSGSTDYNPSLKSRVTISVDTSKNQFSLRLTSVTAADTAVYYCARVPGSYDSDVWGQGTMVTVSS|QSALTQPPSVSAAPGQKVTISCSGGSNIGSNTVHWYQQLPGTAPKLLIYRNNERPSGIPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDNNSLSVVFGGGTKLTVL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2000\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QIQLVQSGPEVKKPGTSVRVSCKASGDTFSNYAMSWVRQAPGKGLEWMGGIIPIFGTANYAQKFQGRVTISADKSTTTYMELRSEDTAVYYCARGQTIVDYWDYWGQGTLVTVSS|DIQMTQSPSSLSAFPGEAVSLSCRASQSVSYIHWYQQKPGQPPKLLIFGASKSAGVPSRFSGSGSGTEFTLTISSLQSEDFAVYYCQQYNSYPLTFGGGTKVEIR\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVQPGGSLRLSCAASGFTFSNYAMHWVRQAPGKGLEWVSGISGSGTTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARDRSHVYFDVWGQGTMVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVTSTYLAWYQQKRGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTITRLEPEDFACYYCQQYSNWPLTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2100\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFNVYSSSIHWVRQAPGKGLEWVSYISGSGSNTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARSRQWFDPWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISNNLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYRTLALTFGPGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLLESGGGLVQPGGSLRLSCAASGFTFSSYDMHWVRQPPGKGLEWVSTITSGGSITYYNPSLKGRVTISKDSQSINFVYLQMNSLRAEDTAIYYCTRSPDYGDVWGQGTTVTVSS|DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPNLLIYAASSLQSGVPSRFSGSGSGTEFTLTISSLQPEDFATYYCQQLKSDPPTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2200\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVTLRESGPALVKPTQTLTLTCTFSGFSLSTPGGGVGWIRQPPGKALEWLALIYYAGSIDYAPSLKTRLTISKDTSKNQVVLTMTNMDPVDTATYYCVDRNWSAYWGQGTLIV|SVLTQSPATLSVSLGQRATISCKASQNVGSFMNWFQQKPGQPPKLLIYEVSNRPSGVPARFSGSGSGTDFTLTINSLEAEDFAVYYCHQYHNSFWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLEWVAIIWDGSNKYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCAKDYGSGAYWGQGTLVTV|DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYKASSLESGVPSRFSGSGSGTEFTLTITSLQPDDFATYYCQQYNEDPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2300\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFNVSYSSIHWVRQAPGKGLEWVASISPYSGGTSYADSVKGRFTISADTSKNTAYLQMRAEDTAVYYCARLYYGDAWFAYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQYNSYPLTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGITVSSNYMSWVRQAPGKGLEWVSGIFPNRGNTAYNQKFKGRVTMTRDTSISTAYMELRSDDTAVYYCARDRGFRHWGQGTLVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPGQSPQLLIYLGSNRASGVPDRFSGSGSGTDFTLKISRVEAEDVGVYYCMQALQTHPLTFGQGTKLEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2400\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: VQLVESGGGLVQPGGSLRLSCAASGFNVSYYSIHWVRQAPGKGLEWVASISSYYGYTYYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARYRYYGSWFDPWYFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVESSNLDWYQQKPGKAPKLLIYDASNLETGVPSRFSGSGSGTDFTFTISSLQPEDIATYYCQQHYEPPYTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGGSLRLSCAASGFNYYSSMHWVRQAPGKGLEWVSAISGSGDTTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARLGWRDYWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPPTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2500\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQESGPGLVAPSQSLSITCTVSGFSLTNYSVHWVRQPPGKGLEWLGVIWAGGGGTNYNSALMSRVSISRDTSKNQFFLKLSSVTAADTAVYYCAREYYRTYYMDVWGKGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASKNIKSYLSWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQNNSTPYTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNFGMHWVRQAPGKGLEWVAVIWDGEKNYADFA2GVLTGRMSIDTSKNTLYLQMRAEDTAVYYCAREGDWGLDVWGQGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISRYLNWFQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTITSLQPEDFATYYCQQSNYPPPTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2600\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVQSGAEVKKPGASVKVSCKTSGYTFTSYNIHWVRQAPGQRLEWMGWINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCARGTTYYDSWYFDVWGQGTTVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCSASGFTFSSYAMSWVRQAPGKGLEWVSAISSGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCAKDGYGNTYFDYWGQGTLVTVSS|DIVLTQSPLTSEPVPPGTQAVSITCGGSNIGGKNYVSWYQQHPGKAPKLLIYGASNRPSGVPDRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYTTPPTFGPGTRLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2700\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QIQLVQSGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLKWMGWINTYTGEPTYADDFKGRFAFSLETSASTAYLQIKNEDTATYFCARDRWFGAEDFFWGPGTVVTVSS|DIVMTQSPATLSVTPGDRVSLSCRASQSVIRNLAWYQQKSHESPRLLIKYASQSISGIPSRFSGSGSGTDFTLSINSVESEDIADYYCQQWSSNPPTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVKPGGSLRLSCAASGFTFSSYWMNWVRQAPGKGLEWVGRIKSGGSTAYYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARLWGYDLWGQGTMVTVSS|DIQLTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2800\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFNVSYSSIHWVRQAPGKGLEWVAYIYPSYGYTSYADSVKGRFTISADTSKNTAYLQMRAEDTAVYYCARGEGIGPMDYWGQGTLVTVFN|DIQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQYKYVPVTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAITSGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCAREVRGDYWGQGTLVTVSS|EIVMTQSPATLSVSPGERATLSCRASQSVSSNLAWYQQKPGQAPRLLIYGASTRATGIPARFSGSGSGTEFTLTISSLQSEDFAVYYCQQYNNWPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 2900\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQPGAELVRPGTSVKVSCKASGYTFTSYWMQWVKQRPGQGLEWIGAIYPGDGDTNYNGKFKGKALVTLADKSSSTAYMQLSSLTSEDSAVYYCTRRSGIFDYWGQGTTLTVSS|DIVLTQSPASLAVSLGQRATISCRASKSVSASAYYWFQKKPGQPPKLLIYAASYSEVPARFSGSGSGTDFTLTISSLEPEDFAMYYCLQHSSYPPTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLEWMGGIIIFGTANYAQKFQGRVTITADKSTSTAYMELRSEDTAVYYCARDRDYDVHWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQTVSSTSLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3000\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFRAYWMHWVRQAPGKGLEWVAVIWDGSNKFYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDVRGYDDVWGQGTTVTVSS|DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPNLLIYAASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFRDYYMYWVRQAPGKGLEWVAVISYDGSNKFYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARDRVVLRYYFDYWGQGTLVTVSS|AIQMTQSPSSLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPYTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3100\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVQSGAEVKKPGASVKVSCKASGYPFTSYGISWVRQAPGQGLEWMGWISTYNGNTNYAQKFQGRVTMTTDTSTTTGYMELRRLRSDDTAVYYCARDYTRGAWFDPWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSAPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVQPGGSLRLSCAASGFTFSSYYMNWVRQAPGKGLEWVSGINGGTTIANYADTVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCARDVGGYDVFGMDYWGQGTLVTVSS|DIQMTQSPSAMSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPPTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3200\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQESGPGLVKPSETLSVTCIVSGGSISRYYWWWIRQSPGKGLEWIGEIYYHSGSTNYNPSLKSRVTISVDTSKNQFSLNLNSVTAADSAVYYCARDGDYWGQGTLVTVSS|DIQLTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASILQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQLNSYPYTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLIQPGGSLRLSCAASEIFSSTYTIHWVRQAPGKGLEWVSGILSASTYYYSESVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARDLVLAVFYWGQGTLVTVSS|AIQLTQSPSSLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3300\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLVQSGAEVKKPGASVKVSCKASGYTFTSYYMHWVRQAPGQGLEWMGIINPSGGSTNYAQKFQGRVTMTEDTSTDTAYMELSSLRSEDTAVYYCARGDVDYGAMDYWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFIVSRNYMSWVRQAPGKGLEWVSSISSSASYKYADSVKGRFTISRDNAENSLYLQMRAEDTAVYYCARDYGDAIDYWGQGTLVTVSS|DIVLTQSPGTLSLSPGERATLSCRASQSISSSNLAWFQQKPGQAPRLLIYGASTRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3400\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCKASGYTFTSYWMHWVKQRPGQGLEWIGEIHPSDSEGTTYNQKFRGKATLTVDKSSSTAYMQLSSLTSEDSAVYYCARSWYDGFAYWGQGTLVTVSA|DIVLTQSPASLAVSLGQRATISCRASESVDNYGISSMNWFQQKAGQPPKFLIYAASKLESGVPARFSGSGSGTDFSLNIHPVEEDDTAMYFCQQSKGVPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGITVSSNYMSWVRQAPGKGLEWVSVIYSGGTTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARDLVVVGSAMDYWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPLTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - Step 3500\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>\\1</epi><epi>\\1</epi>HGL<epi>\\1</epi><epi>\\...\n",
      "Generated: VQLQQSGAEVKKPGSSVRVSCKASGGTFNNYAISWVRQAPGQGLEWMGGIIPIFGTANYAQKFQGRVTITADRSTSTAYMELSSLRSEDTAVYYCAREGPYAGFDLWGQGTLVTVSS|EIVLTQSPGTLSASPGERATLSCRASQSVGNNLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYEFFGLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLEWMGRIIPILGIANYAQKFQGRVTITADESTDTAYMELSSLRSEDTAVYYCARVSGGHVDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPPTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/llama-antibody-20250812_190413\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model()\n",
    "print(f\"Model saved to {training_args.output_dir}\")\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
