{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3deb958f",
   "metadata": {},
   "source": [
    "# Fine-Tune an LLM for Antibody Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920184da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f381adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs: 2\n",
      "GPU 0: NVIDIA GeForce RTX 5090\n",
      "Memory: 33.7 GB\n",
      "GPU 1: NVIDIA GeForce RTX 3090 Ti\n",
      "Memory: 25.3 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test your GPU setup\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3861480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pdb_id', 'h_chain_id', 'l_chain_id', 'antigen_ids', 'h_chain_seq',\n",
       "       'l_chain_seq', 'antigen_seqs', 'antibody_seqs', 'h_chain_fv_seq',\n",
       "       'l_chain_fv_seq', 'antibody_fv_seqs', 'highlighted_epitope_seqs',\n",
       "       'epitope_residues'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load dataset\n",
    "df = pd.read_csv(\"../data/sabdab/sabdab_training_dataset.csv\")\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8023680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>h_chain_id</th>\n",
       "      <th>l_chain_id</th>\n",
       "      <th>antigen_ids</th>\n",
       "      <th>h_chain_seq</th>\n",
       "      <th>l_chain_seq</th>\n",
       "      <th>antigen_seqs</th>\n",
       "      <th>antibody_seqs</th>\n",
       "      <th>h_chain_fv_seq</th>\n",
       "      <th>l_chain_fv_seq</th>\n",
       "      <th>antibody_fv_seqs</th>\n",
       "      <th>highlighted_epitope_seqs</th>\n",
       "      <th>epitope_residues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8xa4</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>A|B</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...</td>\n",
       "      <td>SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>SCNGLYYQGSCYI[L]HSD[Y]KSFEDAKANCAAESSTLPNKSDVL...</td>\n",
       "      <td>A:ARG 176|A:ASP 146|A:ASP 150|A:ASP 170|A:GLN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9cph</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...</td>\n",
       "      <td>KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...</td>\n",
       "      <td>A:ALA 1116|A:ALA 1122|A:ALA 1128|A:ALA 900|A:A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>E:ARG 429|E:ARG 469|E:ASN 177|E:ASN 197|E:ASN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>J</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>C:ARG 469|C:ASN 197|C:ASN 280|C:ASN 425|C:ASP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9d7o</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>E:ARG 429|E:ARG 469|E:ASN 197|E:ASN 280|E:ASN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id h_chain_id l_chain_id antigen_ids  \\\n",
       "0   8xa4          C          D         A|B   \n",
       "1   9cph          H          L           A   \n",
       "2   9d7i          H          G           E   \n",
       "3   9d7i          J          I           C   \n",
       "4   9d7o          H          G           E   \n",
       "\n",
       "                                         h_chain_seq  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                         l_chain_seq  \\\n",
       "0  EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...   \n",
       "1  AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...   \n",
       "2  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "3  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "4  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "\n",
       "                                        antigen_seqs  \\\n",
       "0  SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...   \n",
       "1  KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...   \n",
       "2  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "3  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "4  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "\n",
       "                                       antibody_seqs  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                      h_chain_fv_seq  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                      l_chain_fv_seq  \\\n",
       "0  EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...   \n",
       "1  AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...   \n",
       "2  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "3  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "4  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "\n",
       "                                    antibody_fv_seqs  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                            highlighted_epitope_seqs  \\\n",
       "0  SCNGLYYQGSCYI[L]HSD[Y]KSFEDAKANCAAESSTLPNKSDVL...   \n",
       "1  KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...   \n",
       "2  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "3  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "4  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "\n",
       "                                    epitope_residues  \n",
       "0  A:ARG 176|A:ASP 146|A:ASP 150|A:ASP 170|A:GLN ...  \n",
       "1  A:ALA 1116|A:ALA 1122|A:ALA 1128|A:ALA 900|A:A...  \n",
       "2  E:ARG 429|E:ARG 469|E:ASN 177|E:ASN 197|E:ASN ...  \n",
       "3  C:ARG 469|C:ASN 197|C:ASN 280|C:ASN 425|C:ASP ...  \n",
       "4  E:ARG 429|E:ARG 469|E:ASN 197|E:ASN 280|E:ASN ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove rows with missing sequences\n",
    "df = df.dropna(subset=['h_chain_seq', 'l_chain_seq', 'antigen_seqs', 'highlighted_epitope_seqs'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17677f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "## Load base tokenizer and model FIRST\n",
    "model_name = \"microsoft/phi-4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map= {'model.embed_tokens': 0, \n",
    "                 'model.layers.0': 0, \n",
    "                 'model.layers.1': 0, \n",
    "                 'model.layers.2': 0, \n",
    "                 'model.layers.3': 0, \n",
    "                 'model.layers.4': 0, \n",
    "                 'model.layers.5': 0, \n",
    "                 'model.layers.6': 0, \n",
    "                 'model.layers.7': 0, \n",
    "                 'model.layers.8': 0, \n",
    "                 'model.layers.9': 0, \n",
    "                 'model.layers.10': 0, \n",
    "                 'model.layers.11': 0, \n",
    "                 'model.layers.12': 0, \n",
    "                 'model.layers.13': 0, \n",
    "                 'model.layers.14': 0, \n",
    "                 'model.layers.15': 0, \n",
    "                 'model.layers.16': 0, \n",
    "                 'model.layers.17': 0, \n",
    "                 'model.layers.18': 0, \n",
    "                 'model.layers.19': 0, \n",
    "                 'model.layers.20': 0, \n",
    "                 'model.layers.21': 0, \n",
    "                 'model.layers.22': 0, \n",
    "                 'model.layers.23': 0, \n",
    "                 'model.layers.24': 0, \n",
    "                 'model.layers.25': 0, \n",
    "                 'model.layers.26': 1, \n",
    "                 'model.layers.27': 1, \n",
    "                 'model.layers.28': 1, \n",
    "                 'model.layers.29': 1, \n",
    "                 'model.layers.30': 1, \n",
    "                 'model.layers.31': 1, \n",
    "                 'model.layers.32': 1, \n",
    "                 'model.layers.33': 1, \n",
    "                 'model.layers.34': 1, \n",
    "                 'model.layers.35': 1, \n",
    "                 'model.layers.36': 1, \n",
    "                 'model.layers.37': 1, \n",
    "                 'model.layers.38': 1, \n",
    "                 'model.layers.39': 1, \n",
    "                 'model.norm': 1, \n",
    "                 'model.rotary_emb': 1, \n",
    "                 'lm_head': 1}, # Use only the first GPU\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16, # Load model in bfloat16 for better performance\n",
    "    low_cpu_mem_usage=True, # Reduce CPU memory usage during loading\n",
    "    max_memory={0: \"30GB\", 1:\"23.5GB\"}  # Limit GPU memory usage to 20GB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aeef2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.layers.32': 1, 'model.layers.33': 1, 'model.layers.34': 1, 'model.layers.35': 1, 'model.layers.36': 1, 'model.layers.37': 1, 'model.layers.38': 1, 'model.layers.39': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}\n"
     ]
    }
   ],
   "source": [
    "# Check current device mapping\n",
    "print(\"Current device map:\", model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d6a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add epitope tokens\n",
    "epitope_tokens = [\"<epi>\", \"</epi>\"]\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": epitope_tokens})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989b8e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(100354, 5120, padding_idx=100349)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (qkv_proj): Linear(in_features=5120, out_features=7680, bias=False)\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear(in_features=5120, out_features=35840, bias=False)\n",
       "          (down_proj): Linear(in_features=17920, out_features=5120, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm((5120,), eps=1e-05)\n",
       "        (post_attention_layernorm): Phi3RMSNorm((5120,), eps=1e-05)\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm((5120,), eps=1e-05)\n",
       "    (rotary_emb): Phi3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=100354, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add amino acid tokens\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "extra_tokens = amino_acids + [\"|\"]\n",
    "new_tokens = [t for t in extra_tokens if t not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings ONCE after adding all tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018d2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:00<00:00, 17577.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert epitope format function\n",
    "import re\n",
    "def convert_epitope_format(sequence):\n",
    "    return re.sub(r'\\[([A-Z])\\]', r'<epi>\\1</epi>', sequence)\n",
    "\n",
    "## NOW create dataset with all tokens available\n",
    "def format_prompt(example):\n",
    "    epitope_seq = convert_epitope_format(example['highlighted_epitope_seqs'])\n",
    "    return {\n",
    "        \"text\": f\"Antigen: {epitope_seq}<|im_end|>\\nAntibody: {example['antibody_fv_seqs']}<|im_end|>\\n\"\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3807a8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100357, 5120, padding_idx=100349)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add task-specific tokens\n",
    "task_tokens = [\"Antigen\", \"Antibody\", \"Epitope\"]\n",
    "tokenizer.add_tokens(task_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd69730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences truncated at max_length=800: 198/9523 (2.1%)\n"
     ]
    }
   ],
   "source": [
    "# Check truncation at 800\n",
    "sequence_lengths = [len(tokenizer(example[\"text\"], truncation=False)[\"input_ids\"]) for example in dataset]\n",
    "truncated_800 = sum(1 for length in sequence_lengths if length > 800)\n",
    "print(f\"Sequences truncated at max_length=800: {truncated_800}/{len(sequence_lengths)} ({100*truncated_800/len(sequence_lengths):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd7f786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:02<00:00, 3635.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Tokenize the dataset\n",
    "def tokenize(example):\n",
    "    encoded = tokenizer(example[\"text\"], truncation=True, max_length=800)\n",
    "    # Make sure labels are a proper list, not nested\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    return encoded\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4ecba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized text:\n",
      "['Antigen', ':', 'Ä SCN', 'GL', 'YY', 'Q', 'G', 'SC', 'Y', 'I', '<epi>', 'L', '</epi>', 'H', 'SD', '<epi>', 'Y', '</epi>', 'K', 'SF', 'ED', 'AK', 'AN', 'CAA', 'ES', 'ST', 'LP', 'NK', 'SD', 'VL', 'TT', 'W', 'LI', '<epi>', 'D', '</epi>', '<epi>', 'Y', '</epi>', 'V', '<epi>', 'E', '</epi>', '<epi>', 'D', '</epi>', '<epi>', 'T', '</epi>', 'WG', 'SD', 'GN', 'P', 'IT', 'K', 'TT', 'SD', '<epi>', 'Y', '</epi>', 'Q', 'DS', '<epi>', 'D', '</epi>', 'VS', '<epi>', 'Q', '</epi>', '<epi>', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Verify tokenization is working with epitope tokens\n",
    "print(\"Sample tokenized text:\")\n",
    "sample_tokens = tokenizer.tokenize(dataset[0]['text'][:200])\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb594211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after removal: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\n",
    "    'pdb_id', 'h_chain_id', 'l_chain_id', 'antigen_ids', 'antigen_seqs',\n",
    "    'h_chain_seq', 'l_chain_seq', 'antibody_seqs',\n",
    "    'highlighted_epitope_seqs', 'epitope_residues','h_chain_fv_seq',\n",
    "       'l_chain_fv_seq', 'antibody_fv_seqs', 'text'\n",
    "])\n",
    "print(\"Columns after removal:\", tokenized_dataset.column_names)\n",
    "# Should show: ['input_ids', 'attention_mask', 'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fa4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the gradient fix to your model\n",
    "if hasattr(model, 'enable_input_require_grads'):\n",
    "    model.enable_input_require_grads()\n",
    "else:\n",
    "    def make_inputs_require_grad(module, input, output):\n",
    "        output.requires_grad_(True)\n",
    "    model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0eecbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data collator\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=False,\n",
    "#     return_tensors=\"pt\",\n",
    "#     pad_to_multiple_of=8, # Pad to multiple of 8 for better performance on GPUs\n",
    "# )\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12048eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,372,800 || all params: 14,666,931,200 || trainable%: 0.0503\n"
     ]
    }
   ],
   "source": [
    " # Configure LoRA\n",
    "## PEFT configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    # target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "    target_modules=[\"o_proj\", \"qkv_proj\"],\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbabff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training arguments to enable wandb logging\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/peleke-{model_name.split('/')[-1]}-0806025\",\n",
    "    per_device_train_batch_size=9,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=25,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=25,\n",
    "    gradient_checkpointing=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\", #\"wandb\",  # Enable wandb reporting\n",
    "    run_name=f\"lora-epitope-{model_name.split('/')[-1]}\",  # Run name for wandb\n",
    "    # optim=\"adamw_torch\",\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    dataloader_num_workers=8,  # Add parallel data loading\n",
    "    dataloader_pin_memory=True,  # Pin memory for faster data loading\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04199b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sequence 1 ===\n",
      "Original: KVFGRCELAAAM[K][R]HGL[D][N][Y]RG[Y][S]LG[N]WVCAAKFESNFNTQATN...\n",
      "Converted: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "------------------------------------------------------------\n",
      "=== Sequence 2 ===\n",
      "Original: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Converted: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Final test_antigens for training callback:\n",
      "Test 1: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</epi><epi>Y</epi>RG<ep...\n",
      "Test 2: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI<epi>R</epi...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_brackets_to_epi(sequence):\n",
    "    \"\"\"Convert [X] format to <epi>X</epi> format\"\"\"\n",
    "    return re.sub(r'\\[([A-Z])\\]', r'<epi>\\1</epi>', sequence)\n",
    "\n",
    "# Convert your bracket sequences to the training format\n",
    "sequences_with_brackets = [\n",
    "    \"KVFGRCELAAAM[K][R]HGL[D][N][Y]RG[Y][S]LG[N]WVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCA[K]KIVSDGNGMNAWVAWRNRCK[G][T][D]V[Q]AW[I][R]GCRL\",\n",
    "    \"NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI[R]G[N]EV[S][Q]IAPGQ[T]GNIADYNYKLPDDFTGCVIAWNSN[K]LDSKPSGNYNYLYRLLRKSKLKPFERDISTEIYQAGNKPCNGVAGPNCYSPLQSYGF[R]P[T][Y][G][V]GH[Q]PYRVVVLSFELLHAPATVCGP\",\n",
    "]\n",
    "\n",
    "# Convert to the exact training format\n",
    "test_antigens = [convert_brackets_to_epi(seq) for seq in sequences_with_brackets]\n",
    "\n",
    "# Verify the conversion\n",
    "for i, (orig, conv) in enumerate(zip(sequences_with_brackets, test_antigens)):\n",
    "    print(f\"=== Sequence {i+1} ===\")\n",
    "    print(f\"Original: {orig[:60]}...\")\n",
    "    print(f\"Converted: {conv[:60]}...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nFinal test_antigens for training callback:\")\n",
    "for i, antigen in enumerate(test_antigens):\n",
    "    print(f\"Test {i+1}: {antigen[:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5831082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class TestGenerationCallback(TrainerCallback):\n",
    "    def __init__(self, model, tokenizer, test_antigens, log_every_n_steps=100, output_file=\"test_generations.txt\"):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_antigens = test_antigens\n",
    "        self.log_every_n_steps = log_every_n_steps\n",
    "        self.output_file = output_file\n",
    "        \n",
    "        # Create/clear the output file\n",
    "        with open(self.output_file, 'w') as f:\n",
    "            f.write(f\"Test Generation Log - Started: {datetime.now()}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    def create_test_prompt(self, antigen_with_epitopes):\n",
    "        return f\"Antigen: {antigen_with_epitopes}<|im_end|>\\nAntibody:\"\n",
    "    \n",
    "    def generate_antibody_test(self, antigen_with_epitopes, max_length=800):\n",
    "        \"\"\"Generate antibody for testing during training\"\"\"\n",
    "        prompt = self.create_test_prompt(antigen_with_epitopes)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate\n",
    "        self.model.eval()\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=200,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\"),\n",
    "                    repetition_penalty=1.1,\n",
    "                )\n",
    "                \n",
    "                # Decode and extract antibody\n",
    "                generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "                if \"Antibody:\" in generated_text:\n",
    "                    antibody_part = generated_text.split(\"Antibody:\", 1)[1]\n",
    "                    if \"<|im_end|>\" in antibody_part:\n",
    "                        antibody_sequence = antibody_part.split(\"<|im_end|>\", 1)[0].strip()\n",
    "                    else:\n",
    "                        antibody_sequence = antibody_part.strip()\n",
    "                else:\n",
    "                    antibody_sequence = \"Generation failed\"\n",
    "                \n",
    "                return antibody_sequence\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "        finally:\n",
    "            self.model.train()  # Put model back in training mode\n",
    "    \n",
    "    def run_test_generation(self, state, phase=\"TRAINING\"):\n",
    "        \"\"\"Run test generation and print/save results\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        header = f\"TEST GENERATION - {phase} - STEP {state.global_step} - {timestamp}\"\n",
    "        \n",
    "        # Print to terminal\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(header)\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Write to file\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"{header}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for i, test_antigen in enumerate(self.test_antigens):\n",
    "            case_header = f\"--- Test Case {i+1} ---\"\n",
    "            input_display = f\"Input: {test_antigen[:60]}{'...' if len(test_antigen) > 60 else ''}\"\n",
    "            \n",
    "            # Generate antibody\n",
    "            antibody = self.generate_antibody_test(test_antigen)\n",
    "            generated_display = f\"Generated: {antibody}\"\n",
    "            \n",
    "            # Print to terminal\n",
    "            print(f\"\\n{case_header}\")\n",
    "            print(input_display)\n",
    "            print(generated_display)\n",
    "            \n",
    "            # Write to file (with full input)\n",
    "            with open(self.output_file, 'a') as f:\n",
    "                f.write(f\"\\n{case_header}\\n\")\n",
    "                f.write(f\"Full Input: {test_antigen}\\n\")\n",
    "                f.write(f\"Generated: {antibody}\\n\")\n",
    "                f.write(f\"Length: {len(antibody)} characters\\n\")\n",
    "        \n",
    "        # Terminal footer\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # File footer\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "    \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test at the beginning of training\"\"\"\n",
    "        print(\"ðŸ§¬ INITIAL GENERATION TEST (Before Training)\")\n",
    "        self.run_test_generation(state, \"INITIAL\")\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test periodically during training\"\"\"\n",
    "        if state.global_step % self.log_every_n_steps == 0 and state.global_step > 0:\n",
    "            self.run_test_generation(state, \"PERIODIC\")\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test at the end of training\"\"\"\n",
    "        print(\"ðŸŽ‰ FINAL GENERATION TEST (After Training)\")\n",
    "        self.run_test_generation(state, \"FINAL\")\n",
    "        \n",
    "        # Add summary to file\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"\\nTraining completed: {datetime.now()}\\n\")\n",
    "            f.write(f\"Final step: {state.global_step}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc859af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the callback\n",
    "test_callback = TestGenerationCallback(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    test_antigens=test_antigens,\n",
    "    log_every_n_steps=50,  # Test every 50 steps\n",
    "    output_file=\"/home/nicholas/Documents/GitHub/peleke/logs/test_generations.txt\"  # Save to logs directory\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:00<00:00, 167215.19 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "ðŸ§¬ INITIAL GENERATION TEST (Before Training)\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - INITIAL - STEP 0 - 2025-08-06 11:15:22\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: Greetings! I'm here to assist you with any questions or topics you might have. What can I help you with today? Whether it's about a specific subject, general knowledge, advice, or just a friendly chat, feel free to ask anything!\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI AccessControlList { \n",
      "    Effect           = \"Allow\" \n",
      "    Principal        = \"*\" \n",
      "    Action           = [ \n",
      "                        \"s3:GetObject\", \n",
      "                        \"s3:PutObject\"\n",
      "                    ] \n",
      "    Resource         = \"arn:aws:s3::${var.bucket_name}/*\"\n",
      "}\n",
      "\n",
      "# Create an S3 bucket\n",
      "resource \"aws_s3_bucket\" \"my_bucket\" {\n",
      "  bucket = var.bucket_name\n",
      "\n",
      "  acl    = \"private\"\n",
      "\n",
      "  policy = data.aws_iam_policy_document.my_bucket_policy.json\n",
      "  \n",
      "  versioning {\n",
      "    enabled = true\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This Terraform configuration does the following:\n",
      "- Defines a variable for your S3 bucket name.\n",
      "- Creates an IAM policy document with permissions to get and put objects in the S3 bucket.\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2212' max='3177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2212/3177 3:52:11 < 1:41:23, 0.16 it/s, Epoch 2.09/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4.902400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.357900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>4.257900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>3.417700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>3.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>3.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>3.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.904600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>3.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.788600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.796700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.862900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.812300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.591900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.540800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.504200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.485600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.577300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.525700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.324700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.421200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.178300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.325800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.344100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.294500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>2.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 50 - 2025-08-06 11:20:46\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELVRPGASVKLSCTASGFNIHWYQQKPGKAPKLLIYSADTAVYYCARLDPFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGRSLRLSCAASGFTFSNYAMSWVRQAPGKGLEWIGEIIPGYEQYVQPGQSPKLLIYDASSLRSSDTAMHWVKQRPGQGLEWMGWINPYNGYNYTSKSRIINPKNTLVTSFGDRVTITCQASQSIISSYEDLTIYYCQQSSGVTVLTQPEDFEWIFMSHDFTLTSKISVEKMTVDYRFWGQGTLVTVSS|ELSVAYSGSTVKAISCKGHTVTVSRASQGIHHYTHSEFVQTKISCTGCSGTDFVCPARVGSDYTQTVSISCSLAEYSVTPVYDVVNQKEFKRDYQLSVSPLTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 100 - 2025-08-06 11:25:44\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVKPGSGSLRLSCAASGFTFSSYMWWMRWIRQPPGKGLEWIGWIYYDGSTYYADSVKDYEYLDSWGHGFRTFSNFGDDVTVS|DIQMTQSPSSLSASVGDRVTITCRASESVSSSWYSAYVHWYQQKPGKAPKLILPDLPDPPEPEDSPTFGGGTKLTVL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGRSLRLSCAASGFTFSNYAMHWVRQAPGKGLEWMGWITAYDGTTDYYMDLTAVSVRSGPGSSVLSDVWGQGTLVTVSS|DIVMTQSSEDTAVYYCARYYCYYDTSYSPWLTVSWYQQKPGQPPKLLIYAASSLGAFAIPGVSNRGTDYYPYWYQQHPYTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 150 - 2025-08-06 11:31:01\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFNIYYADSVSWIRNSNGNTNYAQKFQGRVTMTDTSTSTAYMELRTSEDTAVYYCARDDGSKYFDVWGAGTTVTV|EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKSGPPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFNFSSYWMSWVRQAPGKGLEWIGAIITSGNTNYAQKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCARGYGGWGPGDVFYGSGYTDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISYLAWYQQKPGKAPKLLIYAASSLGVSGVPSRFSGSRSGTSASLTGISSLQPEDFGAIYYCQQYYSDYPPEWFQGTRVKFK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 200 - 2025-08-06 11:36:21\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMNWVRQAPGKGLEWMGWISYSGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARVVQYHDYWGQGTTLTVSS|EIVLTQSPATLSVSPGERVSFSCRASQSIGTDYLAWYQQKPGQPPKLMIYAASSLQSGVPSRFSGSGSGTEFTLTISSLQAEDAATYYCQQYDLTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGASVKLSCKASGYTFTYYMHWVKQRPGKGLEWIGRIINYSGSTYYADSVKGRFTISRDNAKNTLYLQMSSLRSEDTAVYYCARGFDGYWGQGTTLTV|DIQMTQSPSSLSASVGDRVTITCRASQDVSLRLNNILSWYQQKPGQAPRLLIYGASSRATGVPARFSGSGSGTDFTLTINSLQPEDFATYYCQQSLRPFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 250 - 2025-08-06 11:41:38\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFIFNSYSWSWIRQPPGKGLEWVASISSSGGSTYYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARDPHTSYDYWGQGTTLTVSA|DIQMTQSPSSLSASVGDRVTITCRASQSISSNLAWYQQKPGKAPKLLIYDAKSRPSGVVRFSGSKSGTSASLDTSQTINTAELQSEDTAVYYCQGYDPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGAELVKPGASVKMSCKASGYTFTSDWIHWVRQTPEKGLEWVAEIRNNYTDSPKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCARGDYDEYDYPFYFDYWGQGTTLTVSS|SVLTQPPSASGTPGQRVTISCSGSRSITNNTVSWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISSLQAEDVAVYYCHGVGYTSFGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 300 - 2025-08-06 11:46:57\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELVRPGTLVKMSCKASGYSFTNYWMNWVKQRPGQGLEWIIGEINPYAPYTSYNQKFKGKATLTVDKSSSTAYMQLSSLTSEDSAVYYCARADGAFYYWGQGTLVTV|SVLTQPPSVSAAPGQTARISCRGGNNVSWYQHKPGQAPILLIYAASSNLAEAGLPDRFPDVRFSGSGSGTDFTLKISRVEAEDLGVYYCMQGSLIFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSNYAMSWVRQAPGKGLEWVAYIYYSGSTYYADSVKGRFTISRDNAKNTLFLQMRAEDTAIYYCAREAGDVWGAVVTV|DIQMTQSPSSLSASVGDRVTITCRASQSIVNYLNWFQQKPGKAPKLLIYGASSRATGIPARFSGSGSGTDFTLTISSLQPEDIATYYCQQYHPPTFGPGTKVDIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 350 - 2025-08-06 11:52:17\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMNWVRQAPGKGLEWVAVISDTGSNKYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARERDYWFDYWGQGTTLTVSS|DIVLTQSPAIMSAAPGDKVTMTCSASSSVSYIGDWYQQHPGKAPKLMIYKVSNRFSGVPDRFSGSKSGTSASLAISGLQSEDEADYYCATYSNRYPLTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFTFSRYAIMSWVRQTPEKGLEWVSVIYGGSNTYYADSVKGRFTISRDNAKNYLQMNSLRSEDTAMYYCARRFDYDFWGQGTTLTVSS|EIVLTQSPATLSLSPGERATLSCRASQSISTSLGWYQQKPDGTVKLLIYAASNLETGVPSRFSGSGSGTEFTLTISSLQPDDFATYYCQQYDNWPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 400 - 2025-08-06 11:57:29\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGPELVKPGASVKISCKASGYTFTNYWMNWVRQAPGQGLEWMGWIFPSSSTSYADSVKGRFSISRDNSKTLYLQMNSLKTEDTAVYYCARSGYAGGYPDDFWGGTLVTVSS|DIVLTQSPLSLPVSLGDQASISCRSSQSLLHSNGYLHWYQQKPGQPPKLLIYAASSLESGVPARFSGSGSGTDFTLTISSLQPEDIATYYCQQSNEDPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGASVKMSCKASGYTFTDYYMNWVRQAPGQGLEWMGGIIPIFGDGSTTYAQKFQGRVTITADKSSSTAYMELRSDDTAVYYCARGGLGSLWGQGTLVTVSA|DIVMTQSPSSLAMSVGDRSVTCKASQNIGNNTVQWYQQKPGQPPKALIYWASTRESGVPARFSGSGSGTSYSLTISSMEAEDAATYYCQQYGSSPWTFGQGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 450 - 2025-08-06 12:02:59\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCTASGFNIKDTYYMWVRQTPEKRLEWIGRIDPANGYTKYDPKFQGKATITADTSSSTAYLQLSSLTSEDSAVYYCARGSLGDYYYAMDYWGQGTTLTVSS|DIVMTQSPLSLPVSLGEQPSVTLSCKSSQSLLNSGNFLHWYQQKPGQPPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSLQAEDVAVYYCHQHYDPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGTSVKVSCKASGYTFTDYYMNWVRQARGQRLEWMGWIRINPYNGNTKYAQKFQGRVTMTRDTSTSTAYMELSSLRSEDTAVYYCARKYNYFDYWGQGTTLTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWFQQKPGQPPKLLIFGVSNRFSGVPARFSGSGSGTDFTLTISSLQAEDVAVYYCQQSSYPITFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 500 - 2025-08-06 12:08:15\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFNIKNFTFSWVRQTPEKRLEWVAEINSGGSNYYPDSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARPGPFDYWGQGTTLTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTDFTLKISRVEAEDVGYFCQHYSTPRTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSRYGMHWVRQAPGKGLEWVAYIDSTSGGTYYADSVKGRFTISRDNSKNTLYLQMNSLRVEDTAVYYCARDGYYDYWGQGTSVTVSS|DIQMTQSPASLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASTLQSGVPSRFSGSGSGTEFTLTISSLQPEDFATYYCQQYGSSLIFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 550 - 2025-08-06 12:13:22\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASEFTISKFMHWVRQAPGKGLEWVASISSYSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRVEDTAVYYCARDDYYDVWGQGTLVTV|DIQMTQSPSTLSASVGDRVTITCRASKSYAYYWSWYQQKPGKAPKLMIYKVSNRFSGVPSRFSGSRSGTDFTLTINNVQPEDFATYYCQQSQSYPLTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGYEFIFNWMSWVRQAPGKGLEWVAIIWDGSGDTYYADSVGRFTISRDNAKKMFYLELRAEDTAVYYCAKQGKYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASTLQSGVPSRFSGSRSGTDFTLTINSLQPEDFATYYCQQSNFPYTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 600 - 2025-08-06 12:18:34\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFNIFTDYGMHWVRQAPGKGLEWVASISSYYGYTTYYADSVKGRFTISRDNSKSLSLQMRAEDTAVYYCARERVVQDIWGQGTSVTVSS|EIVLTQSPGTLSLSPGERATLSCRASESVRSRYLAWFQQKPGQAPRLLIYGASTRATGVPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYNNWPRTFGGGTRVD\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGRSLRLSCAASGFTFRDYAMHWVRQAPGKGLEWVASISSSTSSGYTYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDKRTDLWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGKVPKLLIYAASTLASGVPSRFSGSRSGTDFTLTISRLEPEDFAVYYCQHYNFPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 650 - 2025-08-06 12:24:02\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFNVYYSIHWVRQAPGKGLEWVASISDYGYTYYPDTVKGRFTISRDDSKNTAYLQMNSLRAEDTAVYYCARDPWSGWFDIWGQGTMVTVSS|DIQMTQSPSTLSASVGDRVTITCRASKSVSIAWLAWYQQKPGEPPKVLIYKTSLLSGVPSRFSGSGSGTEFTLTISSLQPEDIATYFCQQYNNLPPTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVKPGGSLRLSCAASGFTFSYYMSWIRQSPGKGLEWVASISSGSTTSYTAYMDVRGRSGNTASLTISRDTSSKNQFLQLRSVTPEDTAVYYCAREDYFDYWGQGTTLTV|DIVMTQSPLSLPVTPGEPASISCRSSQSIVHSNGNTYLHWYLQRPGQSPQLLIYLGSNRASGVPDRFSGSGSGTDFTLKISRVEAEDVGVYYCMQALQIPGTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 700 - 2025-08-06 12:29:25\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVQSGAEVKKPGSSVKVSCKASGGTFNSAIHWVRQAPGQGLEWMGWISTSYNSGSTNYADSVKFKDKATLTVDKSSSTAYMELRSDDTAVYYCARDLWGPDLDVWGQGTTVTVSS|EIVMTQSPATLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASTRATGVPARFSGSGSGTEFTLTISSLQSEDFAVYYCQQYSFLPRTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVISDGSSTYYADSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCARDPAAEGFGDYWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTEFTLTISSLQPDDFATYYCQQYGSSLNWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 750 - 2025-08-06 12:34:40\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVQPGGSLKLSCAASGFNVSYSSIHWVRQTPEKRLEWVAYISSSGGSTYYADSVKGRFTISRDNSKNYLQMRAEDLAVYYCARERGDGYDFWGQGTTLTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQNGHTYLEWYLQRPGQSPQLLIYLGSNLASGVPSRFSGSGSGTDFTLTISSLQAEDVAVYYCHQSYSTPPTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFTFSRHMSWVRQTPGKGLEWLALILWDSSGNRYSPSLKSRLTSITRDTSKNQFFLQLRSSVTAADTAVYYCARHRAYFGDGWGQGTTLTV|EIVLTQSPGTLSLSPGERATLSCRASQSISTSYMHWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 800 - 2025-08-06 12:39:52\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLQQSGPELVKPGASVKISCKASGYTFSSYWIEWVRQTPEKRLEWMGLINPNSGRTNYNEKFKNLRVTISSRDTSQNAYLQMNSLRAEDTAIYYCTRWDSWGQGTTLTVSS|DIVLTQSPPSVSLGERATQPASISCRSSKSSTYLHWYQQKPGQPPKLLIYASNRYTGVPDRFTGGSGTDFTLTISSLQAADDEAVYYCHQYSNNWPPTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGRSLRLSCAASGFTFSNYAMHWVRQAPGKGLEWVASISSSGGSTYYADSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCAKGSRRFGDSWGQGTLVTVSS|DIQLTQSPSFLSAAVGDRVTITCRASENIYHLAWYQQKPGKAPKLLIYDASSLETGVPSRFSGSGSGTEFTLTISSLQPDDFATYYCQQYNNWPPRYTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 850 - 2025-08-06 12:45:04\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFNVYYYSIHWVRQAPGKGLEWVASISSSSGSTSYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARDLRYWGQGTLVTVSA|DIQMTQSPSSLSASVGDRVTITCRASQSISNNLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQLPYYPALTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCKASGYTFTDYYMHWVKQRPEQGLEWIGRIDPANGGTNFNEKFKNWRFLTLRASTDTAYLELRRLRPEDTGVYYCASDGSGGSALDYWGQGTSVTVSS|DIQMTQSPSSLSASVGDRVTITCQASQDIRRYLNWYQQKPDGTVKLLYTFASSLQGGIPSRFSGSGSGTDFTLTISRLEPEDFAVYYCQQHDNVPRGWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 900 - 2025-08-06 12:50:24\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVIWYDGSNKYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARERGFALDYWGQGTTLTV|DIVMTQTPLTLSVTIGQPASISCRSSQSLLHSNGKNYLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCQQYYSYPRTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFSFYSSYGMHWVRQAPGKGLEWVAVITWDGLDKYPDSVKGRFTISRDNAKNTLYLQMRAEDTAVYYCARVAYGYYYDYWGQGTTLTV|DIVMTQSPLSLSVTPGEPASISCRSSQTIDNNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISDLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 950 - 2025-08-06 12:55:44\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELVRPGTSVKISCKASGYAFSSYWIEWVKQRPGHGLEWIGEINPNNGGTNYNEKFKDKATLTADKSSSTAYMQLSSLTSEDSAVYYCARERGDGYFAVWGAGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLHWYQQKPGEAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAIIWDGSNKYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCAREYEGALDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGRAPKLLIFDASTLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQGYSTPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1000 - 2025-08-06 13:00:57\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVASISSSTSYNIYYADSVKGRFTISRDNSKNILYLQMRAEDTAVYYCARVYSYGSWYFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSINIGLAWYQQKPGKVPKLLIYSSLASQTGVPSRFSGSGSGTEFTLTISRLEPEDFAIYYCQQYNNWPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLIQPGGSLRLSCAASGFIVSSNYMSWVRQAPGKGLEWVASISSYYGYTTYYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARGSGYLWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASTLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQANSFPPTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1050 - 2025-08-06 13:06:12\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFIFSSYWMHWVRQTPEKRLEWVASISNSGGYTYYADSVKGRFTISRDNAKNSLYLQMRAEDTAIYYCARDPPLGSDWGQGTAVTVSS|DIVMTQSPSSLTVSVGDRVTITCRASEDIYSNLAWYQQKPGKAPKLLIYKTSTLASSGVPSRFSGSGSGTEFTLTISRLEPEDFAVYYCQQYDNWPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFRNYAMSWVRQAPGKGLEWVSAISSSGGSTYYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARDGPYYYGYFAVWGAGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQRSFPVTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1100 - 2025-08-06 13:11:29\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLQQPGAELVKPGASVKLSCTASGFNIKDYYMTWVKQRPEQGLEWIGRIDPANGHTNYNEKFKNRVTLTADKSSSTAYMQLSSLASEDSAVYYCARERGDGYAMDYWGQGTTLTVSS|DIQMTQSPSSVSASVGDRVTITCRASQSISSWLAWYQQKPGRAPKLLISAASTLQSGVPSRFSGSGSGTEFTLTISTLRPEDFATYYCQQSYEDPYTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPDKGLEWVALIKSGGTSAKYDTSVKGRFTISRDNAKNTLYLEMSSLRSEDTAMYYCARRRGYYYAYWGQGTLVTVSA|DIQMTQSPSTLAASPAAVTTINCPGSQQTYLNWLTQRASESIIYWYRKNPGPRPPRRLIYRGAISIRRFSGSDRRSASIDGYTNQPEDEAIYYCMHFWSNHTPVFGAGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1150 - 2025-08-06 13:16:44\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLQQSGAELVRPGTSVKLSCKASEYTFTNYGMNWVKQRPEQGLEWIGRIYPGDGDTNYNEKFQKFKDKATLTADKSSSTAYMQLSSLTSEDSAVYYCARERFDYWGQGTTVTVSS|DIVMTQSPLSLPVTLGQPASISCRSSQDGNTYLEWYLQKSHGESPRLLIKYVSASSLESGVPDRFIGSGSGTDFTLKISRVEAEDVGVYYCMQTYSYPWTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGAELVRPGASVKLSCKASGYTFTDYYIHWVKQRPEQGLEWIGRIYPGDGDTNYNEKFKDKATLTVDKSSSTAYMQLSSLTSADSEAVYYCARQTYFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISNNLGWYQQKPGKAPKLLIFAAASYRAKGVNRFEGGGTKLEIKLTPDDSVATFMIDQQTTEDFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1200 - 2025-08-06 13:21:52\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFIFDDYTIHWVRQAPGKGLEWVASISSSSSTSYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDPFFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYTPLTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFPFSRYIHWVRQAPGKGLEWVASISSSSGSTSYADSVKGRFTISRDNAKNTLYLQMSSLRAEDTAVYYCAKHRSRPRDVFAYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWFQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1250 - 2025-08-06 13:27:07\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFIFSSYSMNWVRQTPEKRLEWVASISSSGGSTSYYPDSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARDGGGYGDYWGQGTLVTVSA|EIVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVKPGGSLRLSCAASGFTFSNFAMSWVRQSPEKGLEWVAIIWDGSNNYYSGYAESVKGRFTISRDNARNTLYLEMSSLRSEDTAIYYCARAQGDGYAMDYWGQGTSVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1300 - 2025-08-06 13:31:53\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQQSGAELARPGASVKLSCKASGYTFISYWMHWVKQRPGQGLEWIGRIYPGGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDRGYYDYWGQGTTLTVSS|DIQLTQSPSSLVVSVGEKVTMSCKSSQSLLYSSNQKNYLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVQAEDLAVYYCHQYNNWLPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGGSLRLSCAASGFTFSNFAMSWVRQAPGKGLEWVASISSSSGSTSYADSVKGRFTISRDNAKNSLFLQMNSLRVEDTAIYYCARTYSGRRDYGMDYWGQGTTLTVSS|DIVMTQSPSTLSASTGERVSLSCRASRSVNSSLGWYQQKPGQPPRLLIYSASYRYTGVPDRFTGSGSGTDFTLTISRVEPEDFAVYYCQQYGNSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1350 - 2025-08-06 13:37:24\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFRDYGMHWVRQAPGKGLEWLALIWSDDDKRYSPSLKSRLTISLDTSKNQYYLKAEDTGTYFCARFDIWDPWGQGTLVTV|DIQMTQSPSSLSASVGDRVTITCRASQSISTNYLNWYQQKPGKAPKVLIYAASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFGGYFCQQGNIYPFTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQSPGKGLEWLALIWWDGSNNRYADSVKGRFTISRDNSKNMLYLQMRAEDTAVYYCAKDGYSGDLWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVDNYLGWYQQKPGQAPRLLIYGASSRESIPSRFVGSGSGTEFTLTISSLQSEDFAVYYCQQYGDGPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1400 - 2025-08-06 13:42:52\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFNVYSSIHWVRQAPGKGLEWVASISSYYGYTSYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARLYSTSYWGQGTLVTVSS|EIVMTQSPATLSVSPGERATLSCRASQSVDNYLAWYQQKPGQAPRLLIYDASSRATGIPARFSGSGSGTEFTLTISSLQSEDFAVYYCQQYNNWPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASGITVSSNYMSWVRQTPDKRLELVATIGTTSGGSTYYADSVEGRFTISRDNARNILYLQMSSLKSEDTAMFYCARDQRDYGMDVWGKGTTVTVSS|EIVMTQPSPATLSVSPGERATLSCRASESVSSDLAWYQQKPGEAPKLLIYEASSRHTGVPSRFSGSRSGTDFTLTISRLEPEDFAVYYCQQYNNWPPRTFGQGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1450 - 2025-08-06 13:47:56\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELVKPGASVKLSCTASGFNIKDTYMYWVRQAPGQGLEWMGWIKAYGGNTDYSPSFQGQVTMSLDKSTSTAYLHISSLKSEDSAVYYCARDLYGSYFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQGISNYLNWYQQKPGKVPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISNLQPDDFATYYCQQYKYVPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAIIWDGSNTRYAEVKGRFTISRDDSKNTLYLQMRAEDTAVYYCARGFYGSSDVWGQGTTVTVSS|EIVLTQSPAIMSASPGEKVTMTCSASSSVSYMHWYQQKPGSSPKLWIYSTSNLASGVPARFSGSGSGTSYSLTISSMETEDAATYYCHQWDSNPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1500 - 2025-08-06 13:53:26\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFIFDNYYMYWVRQAPGKGLEWVASISSSSGSTSYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLVVVVDIWGQGTMVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLHWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSNNYPITFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLEWVSGINNSGSIGYAASVKGRFAISRDNPKNTLYLEMRAEDSAIYYCARGAYGDLWGQGTLVTVSS|SIVMTQTPASVEAAVGGTVTIKCQASQSINSFLNWYQQKPGEPPKLLIYASNLESDGVSSRFVFGSGSGTEFTLTITSLQAEDIAYYCQALSNYPWTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1550 - 2025-08-06 13:58:34\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFRNYGMHWVRQAPGKGLEWVAFIRYDGGNKYYADSVKGRFIISRDNSKNTLYLQMRAEDTAVYYCARHVLDDFDIWGQGTLVTV|ALTQPPSVSGSPGQSVTISCTGTSSDVGGYNYVSWYQQHPGKAPKLMIYEVSKRPSGVSNRFSGSKSGNTASLTISGLQAEDEADYYCSSYTTSSTWVFGGGTKLTV\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVQSGPEVKKPGTSVKVSCKASGFTFSRYAMSWVRQAPGRGLEWMGWIFTSGTINYAQNFQGRVTITADRSTSTAYLELRSEDTAVYYCAKHGDYDYDSSWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVDYLGWYQQKRGQEPSPRLLIKYASESISKSRSGIPSRFSGSGFGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEI\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1600 - 2025-08-06 14:03:42\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLVESGGGVVKPGGSLKLSCAASGFTFSNYGMNWVRQTPEKRLEWVASISDGGSNNYNYPDKFKGKATLTADTSSSTAYMELSSLTSEDSAVYYCARERDFGDYWGQGTLVTVSS|DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKSGQPPKLLIYWASTRESGVPDRFSGSGSGAEFTLTISSLQAEDVAVYYCQHYDNWPYTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSYYAMHWVRQAPGKGLEWVAVISDGSNKYYADSVKGRFTISRDNSKNTLYLQMNSLRVEDTAIYYCTRGTTGDYWGPGTLVT|EIVLTQSPATLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASTRATGIPARFSGSGSGAEFTLTISSLQSEDFAVYYCQQYNNWPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1650 - 2025-08-06 14:08:48\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASEFTVSRSNYMSWVRQAPGKGLEWVSVISSAGGITYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLVVGDWAMDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQDVSTDLHWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVQSGPEVKKPGTSVKVSCKASGYIFDFHYMYWVRQAPGQGLEWMGWINTYGTTNYAQKFQGRVTITRDTSASTAYMELRSEDTAVYYCARDPPHYDHWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSINKWLAWYQQKPGKAPKALIYAASSLESGVPSRFSGSGSGTEFTLTISTLRPEDFATYYCQQSNEDPRTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1700 - 2025-08-06 14:13:51\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSSNYMSWVRQTPEKRLEWVASISSGSSTSYYPDSVKGRFTISRDNAENTLYLQMSSLRAEDTAVYYCARDGFAYYYAMDYWGQGTSVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPGQSPHLLIYLGSNRASGVPDRFSGSGSGTDFTLKISRVEAEDVGVYYCMQALQTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASAFTFSSYDMHWVRQAPGKGLEWVSVIYPGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLVGVDDDYWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSISTTYLNWFQQKVGQAPRLLIKYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1750 - 2025-08-06 14:19:03\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFTFSTYSMNWVRQTPEKRLEWVASISSSGGSTYYLDSVKGRFTISRDNAKNSLYLQMSSLRAEDTAIYYCTRWFGDYWGQGTLVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSLVHSNGYNYLDWYLQKPGQSPQLLIYLGSNRASGVPDRFSGSGSGTDFTLKISRVEAEDVGVYYCMQQWNHPPTFGGGTKVDIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGASVKMSCKASGYTFTDYYIHWVKQRPGQGLEWIGAIYPGDGGTKYNEKFKNATLTVDTSASTAYMELSSLRSEDTAVYYCARETHFYDVWGQGTTVTVSS|DIVMTQSPDSLAVSLGERATINCKSSQSLLNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCQQYYSTPRTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1800 - 2025-08-06 14:24:17\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFTFSNYDMNWVRQSPEKRLEWVASISAGGSTYTYYGDSVKGRFTISRDNARNTLYLQMSSLRAEDTAIYYCARVVGYVDYWGQGTTLTVSS|DVVMTQTPLTLSVTIGQPASISCRSTQSVLLSWMNKVYLRRGNNKDGSQFLKSLSASGDVCQQYPTTGVPDRFSGSRSGTDFTLKIRVEIKLLEPEDLGVYIFGGGTKLTVL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSNYWMNWVRQSPEKGLEWVASISSGSTTYTTDYSPSERFKDRVTITRDTSKNAYLQMNSLRPEDTAVYYCAREGHTIGLDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWFQHKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTINSLQPEDIATYYCQQDDELPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1850 - 2025-08-06 14:29:37\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGPELVRPGASMKLSCTASGFNIKDYYMYWVKQRPEQGLEWIGWIDPANDTTYNPSLKFKASATATDTHKVMTADTSSNTAYMQKSLTSEDSAVFYCARLGDGYDYWGQGTTLTVSS|DIVLTQSPASLAVSLGQRATISCRASESVDSYGYSFMHWYQQKPGQPPKLLIYLASNLESGVPARFTGSGSGTDFTLTISSVQAEDLAVYYCQQHYSTPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVKPGGSLRLSCAASGFTFSSYAMSWVRQSPEKGLEWVAEIRSGGSTYYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCAREGVTGDFDYWGQGTTLTVSS|DIQMTQSPSTLSASTGDRVTITCRASESISNWVAWYQQKPGKAPKVLIYDTSNLASGVPSRFSGSGSGTEFTLTISSLQPDDFATYYCQQYNNYPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1900 - 2025-08-06 14:34:55\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFIFSSSSIHWVRQAPGKGLEWVASISSYYGSTSYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARDLDWGWDIWGQGTLVTV|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGKVPKLLIYAASSLESGVPSRFSGSGSGTEFTLTISRVEPEDFAIYYCQQYNSTPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGAELARPGASVKMSCKASGYIFTDYWMHWVKQRPGQGLEWIGAIYPGDGDTKYNEKFKGKATLTADKSSSTAYMQLSSLTSEDSAVYYCARDDDGYYFDYWGQGTTLTVSS|DIVMTQSPDSLAVSLGERATINCKSSQSLLHSNGNTYLHWYLQKPGQPPNLIIRYSNLESGVPDRFSGSGSGTDFTLNINSVEEEDVGVYYCMQEHTLFPFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1950 - 2025-08-06 14:40:02\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCTASGFNIKDTYMHWVKQRPEQGLEWIGRIDPANGYTGYDPKFQGKATITTDTFSNTAYLQLSSLTSEDTAVYYCARSTGGSGYSFDIWGQGTMVTVSS|DIVMTQSQKFMSTSVGDRVSVTCEASQNIDKLNLAWYQQKPVGQPPKLLIFSAASTRESGVPDRFTGSGSGTDFTLTINNVQPEDFGMYFCQHHYYPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVQSGTEVKKPGESLRISCRASGYEFNFYWIGWVRQMPGKGLEWMGIIYPGDSETRYSPSFQGQVTISVDTSISTAYLQWSSLKASDTAMYYCARSDRGYDYWGQGTTLTVSS|DIQLTQSPDSLAVSLGERATINCKSSQSVLYSSINKNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCQQYYSTPYTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 2000 - 2025-08-06 14:45:41\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAISAGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLARVFDYWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASKGIYSNYVNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTEFTLTIGSLQPDDFATYYCFQGSHVPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGAELVKPGASVKMSCKASGYTFTDYYMNWVKQRPEQGLEWIGRIDPANGDTKYDPKFQGKATITTDTFSNTAYMQLSSLTSEDTAVYYCARGGYAMDYWGQGTSVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISRFNWYQQKPGKAPKVLISEVSNLEGGVPSRFSGSGSGTDFTLTITSLQPDDFATYYCQQYNNYPWTFGQGTKLEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/Documents/GitHub/peleke/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 2050 - 2025-08-06 14:51:07\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVASISSSGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARPPDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASKGIYSNLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVESGGGVVQPGRSLRLSCAASGFPFSSYGMSWVRQAPGKGLEWLGLIGIWNNHSNRYYADSVKGRFTISRDNARNTLYLQMNSLRPEDTAVYYCAREGSGTYGNWGQGTTLTVSS|DIQMTQSPSTLSASVGDRVTITCRASSIRSNFLNWYQQKPGKAPKLLIYDASNLETGVPSRFSGSGSGTDFTFTISSLQPEDIATYYCLQQRNNLPRTFGPGTKVDIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 2100 - 2025-08-06 14:56:26\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVRPGGSLRLSCAASAFTFNNYMHWVRQAPGKGLEWVAYISSSGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLPYYYDDIWGQGTLVTVSS|SYELTQPPSVSVSPGQTARITCSGDALPKQYAYWYQQKPGQAPVLVIYDNTERPSGIPERFSGSSSGTTVTLTISGVQAEDDKATYFCGTWDWVVFGGGTKLTVG\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSNFAMHWVRQTPGKGLEWVALIYGNGDTDYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARGDSSGWYYYYGMDVWGQGTTVTVSS|DIQLTQSPSSLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 2150 - 2025-08-06 15:01:41\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFTFSSYTMNWVRQSPEKRLEWVASISSSGSTYYTDSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARERDYWGQGTLVTVSS|IQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSSSSLITFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLIQPGGSLRLSCAASGVTVSRNYMSWVRQAPGKGLEWVSVMFSGGSTFYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDLRDYYGDVWGQGTTVT|IVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASSRAPGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQFGDSPRTFGQGTKVE\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 2200 - 2025-08-06 15:06:32\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCKASGYTFTSYNMHWVRQAPGQRLEWMGWIKGSGSTNYAQKFQDWVTMTRDTSTTTAYMELRSDDTAIYYCARDPFHYDFWGQGTTLTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVALISDGSNKDYARFLRGRVTITADESTDTAYMELSSLRSEDTAVYYCARSDYGTCYYYGLDVWGQGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASSSVSSSNVAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQYNNFPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up SFTTrainer\n",
    "from trl import SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    callbacks=[test_callback],  # Log every 50 steps\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Finish wandb run\n",
    "#wandb.finish()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model()\n",
    "print(f\"Model saved to {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cfebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87484d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c239d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ff22ec",
   "metadata": {},
   "source": [
    "### This script is used to clear vram. For testing purposes only and when you want to clear the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf5eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory before: 0.00 GB allocated\n",
      "GPU Memory reserved: 0.00 GB reserved\n",
      "No previous model to clear\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "# Clear any existing models from GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check current GPU memory usage\n",
    "print(f\"GPU Memory before: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB allocated\")\n",
    "print(f\"GPU Memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB reserved\")\n",
    "# If you have a model loaded, delete it first\n",
    "try:\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Previous model cleared from memory\")\n",
    "except:\n",
    "    print(\"No previous model to clear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
