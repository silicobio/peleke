{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3deb958f",
   "metadata": {},
   "source": [
    "# Fine-Tune an LLM for Antibody Sequence Generation\n",
    "\n",
    "Model: meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920184da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f381adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA H100 NVL\n",
      "Memory: 99.9 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os, re\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test your GPU setup\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3861480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pdb_id', 'h_chain_id', 'l_chain_id', 'antigen_ids', 'h_chain_seq',\n",
       "       'l_chain_seq', 'antigen_seqs', 'antibody_seqs', 'h_chain_fv_seq',\n",
       "       'l_chain_fv_seq', 'antibody_fv_seqs', 'highlighted_epitope_seqs',\n",
       "       'epitope_residues'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load dataset\n",
    "df = pd.read_csv(\"../data/sabdab/sabdab_training_dataset.csv\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8023680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>h_chain_id</th>\n",
       "      <th>l_chain_id</th>\n",
       "      <th>antigen_ids</th>\n",
       "      <th>h_chain_seq</th>\n",
       "      <th>l_chain_seq</th>\n",
       "      <th>antigen_seqs</th>\n",
       "      <th>antibody_seqs</th>\n",
       "      <th>h_chain_fv_seq</th>\n",
       "      <th>l_chain_fv_seq</th>\n",
       "      <th>antibody_fv_seqs</th>\n",
       "      <th>highlighted_epitope_seqs</th>\n",
       "      <th>epitope_residues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8xa4</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>A|B</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...</td>\n",
       "      <td>SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>SCNGLYYQGSCYI[L]HSD[Y]KSFEDAKANCAAESSTLPNKSDVL...</td>\n",
       "      <td>A:ARG 176|A:ASP 146|A:ASP 150|A:ASP 170|A:GLN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9cph</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...</td>\n",
       "      <td>KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...</td>\n",
       "      <td>A:ALA 1116|A:ALA 1122|A:ALA 1128|A:ALA 900|A:A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>E:ARG 429|E:ARG 469|E:ASN 177|E:ASN 197|E:ASN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>J</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>C:ARG 469|C:ASN 197|C:ASN 280|C:ASN 425|C:ASP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9d7o</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "      <td>E:ARG 429|E:ARG 469|E:ASN 197|E:ASN 280|E:ASN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id h_chain_id l_chain_id antigen_ids  \\\n",
       "0   8xa4          C          D         A|B   \n",
       "1   9cph          H          L           A   \n",
       "2   9d7i          H          G           E   \n",
       "3   9d7i          J          I           C   \n",
       "4   9d7o          H          G           E   \n",
       "\n",
       "                                         h_chain_seq  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                         l_chain_seq  \\\n",
       "0  EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...   \n",
       "1  AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...   \n",
       "2  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "3  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "4  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "\n",
       "                                        antigen_seqs  \\\n",
       "0  SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...   \n",
       "1  KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...   \n",
       "2  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "3  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "4  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "\n",
       "                                       antibody_seqs  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                      h_chain_fv_seq  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                      l_chain_fv_seq  \\\n",
       "0  EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...   \n",
       "1  AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...   \n",
       "2  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "3  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "4  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "\n",
       "                                    antibody_fv_seqs  \\\n",
       "0  QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "2  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "3  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "4  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                            highlighted_epitope_seqs  \\\n",
       "0  SCNGLYYQGSCYI[L]HSD[Y]KSFEDAKANCAAESSTLPNKSDVL...   \n",
       "1  KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...   \n",
       "2  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "3  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "4  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...   \n",
       "\n",
       "                                    epitope_residues  \n",
       "0  A:ARG 176|A:ASP 146|A:ASP 150|A:ASP 170|A:GLN ...  \n",
       "1  A:ALA 1116|A:ALA 1122|A:ALA 1128|A:ALA 900|A:A...  \n",
       "2  E:ARG 429|E:ARG 469|E:ASN 177|E:ASN 197|E:ASN ...  \n",
       "3  C:ARG 469|C:ASN 197|C:ASN 280|C:ASN 425|C:ASP ...  \n",
       "4  E:ARG 429|E:ARG 469|E:ASN 197|E:ASN 280|E:ASN ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove rows with missing sequences\n",
    "df = df.dropna(subset=['h_chain_seq', 'l_chain_seq', 'antigen_seqs', 'highlighted_epitope_seqs'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a04b83bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export HF_HOME=\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/colby-h100-01-ci/code/.cache/huggingface/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17677f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:05<00:00, 16.46s/it]\n"
     ]
    }
   ],
   "source": [
    "## Load base tokenizer and model FIRST\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16, # Load model in bfloat16 for better performance\n",
    "    cache_dir=\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/colby-h100-01-ci/code/.cache/huggingface/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989b8e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128260, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add epitope tokens\n",
    "epitope_tokens = [\"<epi>\", \"</epi>\"]\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": epitope_tokens})\n",
    "\n",
    "## Add amino acid tokens\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "extra_tokens = amino_acids + [\"|\"]\n",
    "new_tokens = [t for t in extra_tokens if t not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "## Add task-specific tokens\n",
    "task_tokens = [\"Antigen\", \"Antibody\"]\n",
    "tokenizer.add_tokens(task_tokens)\n",
    "\n",
    "## Set pad token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "## Resize model embeddings ONCE after adding all tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018d2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:00<00:00, 10685.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Epitope and Prompt Formatter function\n",
    "def format_prompt(example):\n",
    "    epitope_seq = re.sub(r'\\[([A-Z])\\]', r'<epi>\\1</epi>', example['highlighted_epitope_seqs'])\n",
    "    return {\n",
    "        \"text\": f\"Antigen: {epitope_seq}<|im_end|>\\nAntibody: {example['antibody_fv_seqs']}<|im_end|>\\n\"\n",
    "    }\n",
    "\n",
    "## Create dataset with all tokens available\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd69730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences truncated at max_length=800: 267/9523 (2.8%)\n"
     ]
    }
   ],
   "source": [
    "# Check truncation at 800\n",
    "sequence_lengths = [len(tokenizer(example[\"text\"], truncation=False)[\"input_ids\"]) for example in dataset]\n",
    "truncated_800 = sum(1 for length in sequence_lengths if length > 800)\n",
    "print(f\"Sequences truncated at max_length=800: {truncated_800}/{len(sequence_lengths)} ({100*truncated_800/len(sequence_lengths):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbd7f786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:04<00:00, 2179.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Tokenize the dataset\n",
    "def tokenize(example):\n",
    "    encoded = tokenizer(example[\"text\"], truncation=True, max_length=800)\n",
    "    # Make sure labels are a proper list, not nested\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    return encoded\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4ecba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized text:\n",
      "['Antigen', ':', 'Ä SCN', 'GL', 'YY', 'Q', 'G', 'SC', 'Y', 'I', '<epi>', 'L', '</epi>', 'H', 'SD', '<epi>', 'Y', '</epi>', 'K', 'SF', 'ED', 'AK', 'AN', 'CAA', 'ES', 'ST', 'LP', 'NK', 'SD', 'VL', 'TT', 'W', 'LI', '<epi>', 'D', '</epi>', '<epi>', 'Y', '</epi>', 'V', '<epi>', 'E', '</epi>', '<epi>', 'D', '</epi>', '<epi>', 'T', '</epi>', 'WG', 'SD', 'GN', 'P', 'IT', 'K', 'TT', 'SD', '<epi>', 'Y', '</epi>', 'Q', 'DS', '<epi>', 'D', '</epi>', 'VS', '<epi>', 'Q', '</epi>', '<epi>', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Verify tokenization is working with epitope tokens\n",
    "print(\"Sample tokenized text:\")\n",
    "sample_tokens = tokenizer.tokenize(dataset[0]['text'][:200])\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb594211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after removal: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\n",
    "    'pdb_id', 'h_chain_id', 'l_chain_id', 'antigen_ids', 'antigen_seqs',\n",
    "    'h_chain_seq', 'l_chain_seq', 'antibody_seqs',\n",
    "    'highlighted_epitope_seqs', 'epitope_residues','h_chain_fv_seq',\n",
    "       'l_chain_fv_seq', 'antibody_fv_seqs', 'text'\n",
    "])\n",
    "print(\"Columns after removal:\", tokenized_dataset.column_names)\n",
    "# Should show: ['input_ids', 'attention_mask', 'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6fa4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the gradient fix to your model\n",
    "if hasattr(model, 'enable_input_require_grads'):\n",
    "    model.enable_input_require_grads()\n",
    "else:\n",
    "    def make_inputs_require_grad(module, input, output):\n",
    "        output.requires_grad_(True)\n",
    "    model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0eecbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data collator\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=False,\n",
    "#     return_tensors=\"pt\",\n",
    "#     pad_to_multiple_of=8, # Pad to multiple of 8 for better performance on GPUs\n",
    "# )\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12048eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,097,152 || all params: 8,032,391,168 || trainable%: 0.0261\n"
     ]
    }
   ],
   "source": [
    " # Configure LoRA\n",
    "## PEFT configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    # target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "    target_modules=[\"o_proj\", \"qkv_proj\"],\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbabff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    # output_dir=f\"../models/peleke-{model_name.split('/')[-1]}-0806025\",\n",
    "    output_dir=f\"../models/peleke-llama-3.1-8b-instruct\",\n",
    "    per_device_train_batch_size=9,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=25,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=25,\n",
    "    gradient_checkpointing=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\", #\"wandb\",  # Enable wandb reporting\n",
    "    run_name=f\"lora-epitope-{model_name.split('/')[-1]}\",  # Run name for wandb\n",
    "    # optim=\"adamw_torch\",\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    dataloader_num_workers=8,  # Add parallel data loading\n",
    "    dataloader_pin_memory=True,  # Pin memory for faster data loading\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f04199b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sequence 1 ===\n",
      "Original: KVFGRCELAAAM[K][R]HGL[D][N][Y]RG[Y][S]LG[N]WVCAAKFESNFNTQATN...\n",
      "Converted: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "------------------------------------------------------------\n",
      "=== Sequence 2 ===\n",
      "Original: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Converted: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Final test_antigens for training callback:\n",
      "Test 1: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</epi><epi>Y</epi>RG<ep...\n",
      "Test 2: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI<epi>R</epi...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_brackets_to_epi(sequence):\n",
    "    \"\"\"Convert [X] format to <epi>X</epi> format\"\"\"\n",
    "    return re.sub(r'\\[([A-Z])\\]', r'<epi>\\1</epi>', sequence)\n",
    "\n",
    "# Convert your bracket sequences to the training format\n",
    "sequences_with_brackets = [\n",
    "    \"KVFGRCELAAAM[K][R]HGL[D][N][Y]RG[Y][S]LG[N]WVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCA[K]KIVSDGNGMNAWVAWRNRCK[G][T][D]V[Q]AW[I][R]GCRL\",\n",
    "    \"NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVI[R]G[N]EV[S][Q]IAPGQ[T]GNIADYNYKLPDDFTGCVIAWNSN[K]LDSKPSGNYNYLYRLLRKSKLKPFERDISTEIYQAGNKPCNGVAGPNCYSPLQSYGF[R]P[T][Y][G][V]GH[Q]PYRVVVLSFELLHAPATVCGP\",\n",
    "]\n",
    "\n",
    "# Convert to the exact training format\n",
    "test_antigens = [convert_brackets_to_epi(seq) for seq in sequences_with_brackets]\n",
    "\n",
    "# Verify the conversion\n",
    "for i, (orig, conv) in enumerate(zip(sequences_with_brackets, test_antigens)):\n",
    "    print(f\"=== Sequence {i+1} ===\")\n",
    "    print(f\"Original: {orig[:60]}...\")\n",
    "    print(f\"Converted: {conv[:60]}...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nFinal test_antigens for training callback:\")\n",
    "for i, antigen in enumerate(test_antigens):\n",
    "    print(f\"Test {i+1}: {antigen[:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5831082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class TestGenerationCallback(TrainerCallback):\n",
    "    def __init__(self, model, tokenizer, test_antigens, log_every_n_steps=100, output_file=\"test_generations.txt\"):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_antigens = test_antigens\n",
    "        self.log_every_n_steps = log_every_n_steps\n",
    "        self.output_file = output_file\n",
    "        \n",
    "        # Create/clear the output file\n",
    "        with open(self.output_file, 'w') as f:\n",
    "            f.write(f\"Test Generation Log - Started: {datetime.now()}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    def create_test_prompt(self, antigen_with_epitopes):\n",
    "        return f\"Antigen: {antigen_with_epitopes}<|im_end|>\\nAntibody:\"\n",
    "    \n",
    "    def generate_antibody_test(self, antigen_with_epitopes, max_length=800):\n",
    "        \"\"\"Generate antibody for testing during training\"\"\"\n",
    "        prompt = self.create_test_prompt(antigen_with_epitopes)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate\n",
    "        self.model.eval()\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=200,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\"),\n",
    "                    repetition_penalty=1.1,\n",
    "                )\n",
    "                \n",
    "                # Decode and extract antibody\n",
    "                generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "                if \"Antibody:\" in generated_text:\n",
    "                    antibody_part = generated_text.split(\"Antibody:\", 1)[1]\n",
    "                    if \"<|im_end|>\" in antibody_part:\n",
    "                        antibody_sequence = antibody_part.split(\"<|im_end|>\", 1)[0].strip()\n",
    "                    else:\n",
    "                        antibody_sequence = antibody_part.strip()\n",
    "                else:\n",
    "                    antibody_sequence = \"Generation failed\"\n",
    "                \n",
    "                return antibody_sequence\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "        finally:\n",
    "            self.model.train()  # Put model back in training mode\n",
    "    \n",
    "    def run_test_generation(self, state, phase=\"TRAINING\"):\n",
    "        \"\"\"Run test generation and print/save results\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        header = f\"TEST GENERATION - {phase} - STEP {state.global_step} - {timestamp}\"\n",
    "        \n",
    "        # Print to terminal\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(header)\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Write to file\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"{header}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for i, test_antigen in enumerate(self.test_antigens):\n",
    "            case_header = f\"--- Test Case {i+1} ---\"\n",
    "            input_display = f\"Input: {test_antigen[:60]}{'...' if len(test_antigen) > 60 else ''}\"\n",
    "            \n",
    "            # Generate antibody\n",
    "            antibody = self.generate_antibody_test(test_antigen)\n",
    "            generated_display = f\"Generated: {antibody}\"\n",
    "            \n",
    "            # Print to terminal\n",
    "            print(f\"\\n{case_header}\")\n",
    "            print(input_display)\n",
    "            print(generated_display)\n",
    "            \n",
    "            # Write to file (with full input)\n",
    "            with open(self.output_file, 'a') as f:\n",
    "                f.write(f\"\\n{case_header}\\n\")\n",
    "                f.write(f\"Full Input: {test_antigen}\\n\")\n",
    "                f.write(f\"Generated: {antibody}\\n\")\n",
    "                f.write(f\"Length: {len(antibody)} characters\\n\")\n",
    "        \n",
    "        # Terminal footer\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # File footer\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "    \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test at the beginning of training\"\"\"\n",
    "        print(\"ðŸ§¬ INITIAL GENERATION TEST (Before Training)\")\n",
    "        self.run_test_generation(state, \"INITIAL\")\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test periodically during training\"\"\"\n",
    "        if state.global_step % self.log_every_n_steps == 0 and state.global_step > 0:\n",
    "            self.run_test_generation(state, \"PERIODIC\")\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"Test at the end of training\"\"\"\n",
    "        print(\"ðŸŽ‰ FINAL GENERATION TEST (After Training)\")\n",
    "        self.run_test_generation(state, \"FINAL\")\n",
    "        \n",
    "        # Add summary to file\n",
    "        with open(self.output_file, 'a') as f:\n",
    "            f.write(f\"\\nTraining completed: {datetime.now()}\\n\")\n",
    "            f.write(f\"Final step: {state.global_step}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc859af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the callback\n",
    "test_callback = TestGenerationCallback(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    test_antigens=test_antigens,\n",
    "    log_every_n_steps=50,  ## Test every 50 steps\n",
    "    output_file=\"../logs/test_generations.txt\"  ## Save to logs directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14c7922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/peleke-llama-3.1-8b-instruct/tokenizer_config.json',\n",
       " '../models/peleke-llama-3.1-8b-instruct/special_tokens_map.json',\n",
       " '../models/peleke-llama-3.1-8b-instruct/chat_template.jinja',\n",
       " '../models/peleke-llama-3.1-8b-instruct/tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save tokenizer\n",
    "tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9523/9523 [00:00<00:00, 388381.87 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "ðŸ§¬ INITIAL GENERATION TEST (Before Training)\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - INITIAL - STEP 0 - 2025-08-15 01:20:45\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: <|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|eot_id|>: KVFGRCELAAAM<|eot_id|><|start_header_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|start_header_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|start_header_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|end_header_id|>: KVFGRCELAAAM<|end_header_id|>: KVFGRCELAAAM<|eot_id|>: KVFGRCELAAAM<|end_header_id|>: KVFGRCELAAAM<|eot_id|>:<|eot_id|><|start_header_id|>: KVFGRCELAAAM<|eot_id|>: KVFGR\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: NLCPFHEVFNATTFASVFNLCPFHEVN:<|eot_id|>: NLCPFHEVFNATFNATFNFVNATFNFVFNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVNATFNATFNFVN\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1846' max='3177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1846/3177 2:16:24 < 1:38:27, 0.23 it/s, Epoch 1.74/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>4.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.674900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>3.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.550100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>3.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>3.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>3.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>3.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>3.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.922400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.155500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>3.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.926200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>3.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>3.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.933700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.952900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.901300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.794700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.739600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.778700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.727600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.873200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>3.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.674600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.733800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.710200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.547800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 50 - 2025-08-15 01:24:29\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLQQSGAEVVKPSSTISCVGGSHGWSWVRQAPGKGLEWIGGIYYDMHWVRQAPEGGVVSWVRQAPGKGLEWVGALYYCMVWVDYPIGQSRTLLSCTFGSGSTSVTDTSTAYMELSSLRSEDEADYYCQQGNPFYAAPFPATLTVSSGASTTGSIYSLQSLSITEDFATYFTWLNPGDSSTYSMSSTPLTTGVLTFLSSDVSNKTVPKKLVQCPAPGLEILGNVSWFAGHQPYTPTTFGTCEVQHVDTSKLGSNVTLCISCRNPKPFFYPGKPVTLDRFSCATSNNYRPDTRFSGSGTEFTDTSTYYMSWVRQAPGKGLEWVGVYYCHWGDGTDITLTFLSPPSSEDSVKNFK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVSGGSGLDIAGLTCTSSSLTWNSQSLQSPGKVKPGTSVKWSCTASGYTNVTWGPRGDITLGWASIGDISQSNNLEWTEDFGAQPKNMSLNSEDTAMYYCARGDGSSVTVSS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 100 - 2025-08-15 01:27:57\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QSVLTQPPSLAVSGGARVTISCRASEDEADYYCLYWDLQSPGDPSRFSGSKSGNTAYLQLSSLTRPEDFASYFCQQVTVSSEDSALWTQRPEDKSFAGKSYRDYWGQGTTLTVL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSYYAMHWVRQAPGKGLEWVASISCRSGDTSTAYMELSSLRSEDTAVYYCARDSPYDGDYWGQGTTLTVSS|DIVLTQTPSASSGAVVMISCTQSGLINFLSSDRIDGTSYCFDPGYFDYWGQGTLVTVS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSDVTAEDTAVYFCARHGYIPDGSRYDGITGTRVTISDDSH>DLVMTQSPSSLAESGVPDRFTGSGSGSGTDFTLTISSLQPEDFAVYYCQQHNNYGPRTFGSGSGTDFTLTISRVEEDFGYFCLQ\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 150 - 2025-08-15 01:31:38\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLVQSGPEVKKPGTSVKVSCKASGYTFTSYWMHWVRQAPGKGLEWVASISCRSGDNYYADSVKGRFTISRDNSKNLYLQMRAEDTAVYYCARDFALQSYAYWGQGTLVTVSS|DIVLTQSPSTLPSVTLSGTQSPSLIQWKRPGQSLLIGDRNKFSCRAALTGGFTEFTLKVDSSSTAYMELRSVTAADTAVYYCARDLDTYFQTYYGTTTFLLTGVPSRFSGSKSGTDFTLTISRLEPEDFAVYYCQQYHTPDHPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFSFSSYYMWVRQTPEKRLEWVRQAPGKGLEWMGWIPSRRTSGGSTAYMELSSLRSEDTAMYYCARGGGYFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVRSDDAVYYCARADSDYSSDVLAWGRGTKCDTSSTAYMELSSLKTEDLTALYLCARFGGGTKLEIR\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 200 - 2025-08-15 01:35:20\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLQQSGAELVKPGASVKLSCTGSFSSTSYGVHWVRQAPGKGLEWMGYFDYYADSVKGRFTISRDDSKSTLYLQMNSLKTEDTAVYYCARPDKRYFGLGYDFYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQDISNYLNWYQQKPKGKPKKLLIYAASSLQSVGDSGFASYFCRVRFYDGTRYADSVKGRFTISRDNAKNSLYLQMKTEDTALDTAVYYCARFGGGNLWLIGLDVWGQGTTVTVSS|EIVLTQPPSASERATLSCASTGFTFSLNMESEDRSSLRDVSNRGAQFKGLEWLAQYNSSRPTGVPDRFMTCVRDAGDNSSRIRLRGMDYWGQGTLVTVS\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGVSNFSSYTYYMWVRQAPGKGLEWVGFIYPGRDTAVYYCARPEYTPYDFTRGTTLMDTSKYEEVKDKATLTADTAVYYCAREPKVFGTTDITGDL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 250 - 2025-08-15 01:38:59\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGPELVKPGASVKLSCKASGYTFSSYWIGWIRQPPGKGLEWIGEIYPGTNYNEKFKGTKATLTVDKSSSTAYLQLSSLTSEDSAVYYCARDYDVYFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASSQSISNIHWYQQKPGQAPKLIIYSASNLRGVPARFSGSGSGTDFTLKISRVEAEDLGVYYCTQNNPSLKDFSLNVSGNTATLTISGI\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFTFSYYAMHWVRQAPGKGLEWMGWINSGETDYNNQRPSGVPPRFDTSSTAYMELSSLRSEDTAVYYCARWFSLRYGYDYYMDYWGQGTLVTVSA|DIQMTQSPSSLSASVGDRVTITCRASQSVSYSSFYWLQPRTFGSGSGTDFTLTISRLEPEDFAAYYCQQYGNTYPFTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 300 - 2025-08-15 01:42:39\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVQSGAEVKKPGASVKVSCKASGGTFNYGMNWVRQAPGQGLEWMGRIPIAISAYNQKFQGKATMTDTSTSTAYMELSSLTSEDSAVYYCARNGDHWGMDLWGKGTTVTVSS|DIVLTQSPAIMSASPGEKVTLSCTASGVINIGYSNNQRPSGVPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYNYPYTTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFSFYTYMSWVRQAPGKGLEWVASISSIGDYDVYYCARGVYKGRNTMYADSVKGRFTISRDNAKNSLYLQMRAEDTAVYYCARGWGQGTKVTVSS|DIQMTQSPSTLSASVGDRVTITCRASESVYGAYMHWVKQRPGQGLEWIGIDIYPGSNKFSGNTATLTISGTQDESEDIRPYLQMRSVTAADTATYYCQQGYTPRTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 350 - 2025-08-15 01:46:20\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLVQSGPELVKPGASVKLSCTASGFNIHNYYWMSWVRQSPLGGVPDRFSISNKAYAQFQQGQVTMTRSTSTAYMELSSLRSEDTAVYYCARWGRGYDYWGQGTTLTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISSYLAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTDFTLTISRLEPEDFAVYYCQQSYNNPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QLLESGPPGKVAPSWTGRGSTISPGRSSTYYTSWIHWVRQAPGKGPEWMGLIYPSSGTISNTAYLTSSLASVTGDITASSSTAYMELTSEDSAVYYCARTTGTTDGSYDWSWGQGTLTVSS|DIQLTQSPSALSVPGQRATITCRASESGYGTSYLNWFQQKPGKAPKLLIYAASNLETGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSHDTIPRFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 400 - 2025-08-15 01:49:56\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMNWVRQAPGKGLEWVAYISSGYDYADSVKGRFTISRDNSKNLYLQMNSLRVEDTAVYYCARPEYDWGDYWGQGTLVTVSS|EIVMTQSPLSLPVTPGEPASISCRTSNVGSGSYWYQQRPGQSPRLLIFNKNSGTSGVPDRFSGSGSGTDFTLTISRVEAEDVGIYYCFQQGSHWPFTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYYMHWVRQTPEKGLEWVGIIYPGSYTYSVKGRFTISRVDKSKNTLYLQMSSLRSVTTEDTAVYYCARESGGAYWGQGTLVTVSS|EIVMTQSPSTLSASVGDRVTITCRASQSISSYLAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTEFTLTISSLQPEDIATYYCQQWFNFPPYWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 450 - 2025-08-15 01:53:43\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELVRPGARSLRLSCAASGFNIYSYYHWIRQAPGKGLEWIGEINPYSGSTNYNEKFKGKATLTVDKSSSTAYMELSSLRSDDTAVYYCARGGSPLYFDIWGQGTLVTVSS|DIVMTQSPLSLPVSLGDQASISCRSSQSLLHSNGYNLFWYQQKPDGVKPWFQGTKVIYAAGTSVTAYLESEIDPFGKGTTVSVICAEDGGFTYEASKLDIKRFSGSKSGNTASLTISGLQAEDEADYYCVRVWDSDSTIAYLGGG\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSYYAMSWVRQAPGKGLEWVSIWDGSNKTYADSVKGRFTISRDNKNQSLEYMELRSDDTAVYFCARGRGYYGYGLIVSG|DIVMTQSPSSLAVSAGEKVTMSCKSSQVFGNWLAWYQQHPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 500 - 2025-08-15 01:57:21\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFTFSRYWMNWVRQAPGKGLEWVGMIWDGSKSYSPSQIKNLTSISKVDTSKNQVFLKMNSLQTDDTAVYYCARDYDNIWGQGTTVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSGSGTEFTLTISSLQPDDFATYYCQHFWPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSDMNMHWVRQTPEKGLEWVAIIWDGSNTGYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARHGYYGDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASESGIFNNIGALQPPRYLTWTTDTPKRFSGARVLTSVKDSLAVYGTSRASTLGIPARFSGSGSGTDFTLTISSLQPEDFATYYCQQHFWYYPYWTFGTGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 550 - 2025-08-15 02:01:22\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFNIKNYMNHWVRQAPGKGLEWMGISPYSGRTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARDYPGYAMDYWGQGTLVTVSA|EIVLTQSPLTLSVTIGQPASISCKSSQSLLHSNGNTYLHWYLQRPGQSPKLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYYCFQGSHWPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGGSLRLSCAASGFTFSNNTMTWVRQSPGKGLEWVSGISTGRFGTRYNQKFKDKATLTADKSSSTAYMELKSRLTSRDVTSINTLYLRSEDTAVYYCARSSGYDRGVWGQGTLVTVSA|DIQMTQSPSTLSASVGDRVTITCRASESVGSYGMSWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQYNNYPITFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 600 - 2025-08-15 02:05:02\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVKPGGSLKLSCAASGFTFSNYGMHWVRQTPEKRLEWVAYISSGGSYYYSSTLQPPSRISLTNLRSVSDDTAVYLRYTTSRRGDGYWGQGTTLTVSS|DIVMTQSPATLSLSPGERATLSCRASESVSYLNWYQQKPGQAPRLLIGASSRATGVPARFSGSGSGTEFTLTISSLQPEDIATYYCLQHNNPWTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQPGAELVKPGASVKMSCKASGYTFTDYWIHWVRQAPGKGLEWMGWISTYYSGSTYYANSWVKGRFTISRDNAKNTLYLQMRAEDTAVYYCARGEGDGGDGFDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKLLIYKASSLASGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSSSLTYFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 650 - 2025-08-15 02:08:52\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLQQSGAELVKPGASVKLSCTASGFNIKDYYMSWVRQAPGQRLEWMGWISYDGGSTNYNPSLKSRVTISKDNSKSQVFLKMNSLQTDTAMYYCARSPYYDYWGQGTTLTVSS|EIVLTQSPAIMSAAPGDKVTMTCSASSSVSYMYWFQQKSGTSPKRWIHYTRGVPDRFTGSGSATDFTLTIGVPVEAGGETADTVYSCTLQNNFLPLTFSKNQKFGLTATLTKSEDSAIYFCQQYVQTFKYPL\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLQQSGAELVRPGASVKMSCKASGYTFTDYWMNWVKQRPEQGLEWIGRIDPPGGNTKYDPKFQGKATITTDTSKSSTAYMQLSSLTSEDTAVYYCARKDGSHGPYYYGLDVWGKGTTVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQDISNYLNWLWYQQKPDGTIKLLIYAASSLQTSEDLRPSGIPSRFSGSGSGTEFTLTISRLEPEDFAVYYCQQHYSLPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 700 - 2025-08-15 02:12:39\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFNIKFYDAMHWVRQAPGKGLEWVAVISYDGSNKYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARPGGYDYWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYKASSLESGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQYDNLPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVQSGAEVKKPGSSVKVSCKASGGTFNTYAQMHWVRQAPGRGLEWMGWISDGDTRHYDPKFQGRAVLITADKSTTTAYMELSSLRSDDTAVYYCARGLYDYFDIWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASEYDGAVYWYQQKPGKAPKLLIYAASSLESGVPSRFSGSRSGTDFTLTISSLQPEDIATYYCQRYDSYGRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 750 - 2025-08-15 02:16:20\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFVTFTDYGMHWVRQAPGKGLEWVSIIYPGNPSLETSYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAIYYCTRDGVVVWGAGTTVTVSG|DIVLTQSPAIMSAAPGDKVTMTCSASSSVSYIHWYQQKSGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISSLQPEDFATYYCQQSHYLPITFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGLVKPGGSLRLSCAASGFSFTSSYAMHWVRQAPGKGLEWVAVIWYDGSNTYYADSVKGRFTISRDNARNTLYLQMNSLRAEDTAVYYCARAYDYWSWWFDPWGQGTLVTVSS|DIQMTQSPSSLAVSAGEKVTMSCKSSQSLLYSLAWYQQKPGQPPRLLIYWASTRESGVPDRFTGSGSGTDFTLTISRLEPEDFAVYYCQHYDRTWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 800 - 2025-08-15 02:20:00\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QIQLVQSGPELKKPGETVKISCKAYGFKFDTKMHWLKQRPGQGLEWIGGINPSGGTDYNQKFKGKATLTVDKSSSTAYMELRSLTSDDSAVYYCVSAGFDYWGQGTTLTVSS|DIVMTQSPSSLAVSVGDRVTITCRASKSVSTYLAWYQQKPGKAPKLLIYAASSLESGVPARFSGSGSGTEFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASGFTFSNYMAHWVRQAPGKGLEWVASIYYSGGSTYYADSVKGRFTISRDNARNTLYLEMSSLRSEDTAVYYCARHGYGYDFAWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQYNNYPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 850 - 2025-08-15 02:23:40\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGPELVKPGASVKMSCKASGYTFTSYWIHWVKQRPGQGLEWIGEINPNSGTNYNEKFKGKATLTADTSSSTAYMELLSLRSEDTAVYYCARHGKGVSVWGAGTTVTVSS|DIVLTQSPAIMSAAPGDKVTMTCSASSSVSYIHWYQQKSHESPRLLIKYASQSISGIPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSNEDPYTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQPGAELVKPGASVRISCKASGYTFTDYYINHWVKQRPEQGLEWIGRIDPANGDTKYDPKFQGKATITADTSSNTAYLELRSEDTAVYYCAREDYWGQGTLVTVSS|DIVLTQSPAIMSAAPGDKVTMTCSASSSVSYMYWNFLQKPGQSPKLLIYAASNLESGIPARFSGSGSGTDFTLNIHPVEEEDAATYYCHQGSHYPYTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 900 - 2025-08-15 02:27:25\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFRNYGMHWVRQAPGKGLEWVAYIGSGSTYYADSVKGRFTISRDNSKNTLYLQMSSLRAEDTAVYYCARDRYGPGGYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQGISNYLNWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSYYYYGTYFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QLVQSGAEVKKPGESLKVTMCKASGYFSSYYWMNWVKQRPGQGLEWIGMIYPGGTTDYNEKFKGKATLTVDKSSNTAYMDLRSDDTAVYFCARVGDGLGTPWGQGTLVTVSA|DIVMSQSPSSLAVSVGEKVTMSCKSSQSLLYSSNQKNYLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCQQYGYSPLLTFGPGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 950 - 2025-08-15 02:31:09\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVQPGGSMKLSCVASGFSLAYSSSVHWVRQAPGKGLEWVAVIWYDGSNKYYADTVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARAGGSSRYDYWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFAVYYCQQYSTPPTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVKPGGSLRLSCAASGFTFSSYDAMSWVRQTPEKRLEWVAEIRGRGRTYYADSVRGSGRSVYKGRNTFRGMMLMELSSLRPEDTAVYYCARPPSTTTTPWLGQDVWGQGTLVTVSS|DIVMTQSPDSLAVSLGERATINCKSSQSVLTNNNLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLKISRVEAEDLGVYYCFQGSHVPWTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1000 - 2025-08-15 02:34:50\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLVESGGGLVQPGRSLRLSCAASGFTFSYYGMHWVRQAPGKGLEWVAVIWDGSNKYNPSVKGRVTISRDTSKNQFSLKLTAADTAVYYCARQGYGDRGDYWGQGTTLTVSS|EIVLTQSPATLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYDASSRATGIPARFSGSGSGTEFTLTISRLEPEDFAVYYCQQHYNSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLQQSGAELVRPGSSVKMSCKASGYTFTSDWIHWVRQSPGKGLEWMGWINLDGDTRYNQKFQGRVTMTRDTSTSTAYMELSSLRSEDTAVYYCARDVDVYGMDYWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQVGNNYLAWYQQKPGQAPRLLIFGASSRGDFTGTRATLRSDDAVHFMELSGTPRFSGSGTDFTLTISSLQPEDFATYYCQQYNSWPRTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1050 - 2025-08-15 02:38:50\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVISYDGSNKYYADSVKGRFTISRDNSKNTLYLQMNSLKTEDTAVYYCARDGSGSYAMDYWGQGTLVTVSA|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGKAPKLLIYKASTLKTGVPSRFSGSGSGTEFTLTISRLEPEDFAVYYCQQRSNLPLTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSNYAMSWVRQTPEKRLEWVALSSGGSYTYYSDSVKGRFTISRDNARNILYLQMSSLKSEDTAMYYCARESGYYYDYWGQGTLVTVSA|DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYGTYYPDFSRAGVPDRFSGSGSGTDFTLKISRVEAEDLGVYYCMQALRSIPRTFGQGTKVDIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1100 - 2025-08-15 02:42:34\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASEFTFSFYGMHWVRQAPGKGLEWVAYISSSGGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARAGDLFGAMDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSIYSYLAWYQQKPGKAPKLLIYDASSLESGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQHYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASGFTFSNYAMSWVRQAPGKGLEWVSVINSGGSTYYADSVKGRFTISRDNAKKNTLYLQMSSLRAEDTAVYYCARGYGPDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYDASSLKTGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYLTIPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1150 - 2025-08-15 02:46:16\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFDFDSYAIIHWVRQAPGKGLEWVASISSYYGYTSYADSVKGRFTISRDNSKNTLYLQMNSLRVEDTAVYYCARERDYDDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSIDDNWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGASVKMSCKASGYTFTDYYMHWVKQRPGKGLEWMGWINTYGGSANYKSLQVVKNKDTLTVDKSSTAYMELRSLTSEDSAVYYCTRGYYGGAMDYWGQGTTLTVSS|DIQMTQSPSSLAVSVGEKVTMSCKSSQSLLHSNGKAFLPWYQHKPGRAPILLIYAASNLETGVPSRFSGSGSGTDFTLTITSLQPEDFATYYCQHYNSWPFTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1200 - 2025-08-15 02:49:53\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: VQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVAVIWYDGSNKYYADSVKGRFTISRDNSKSTLYLQMNSLRVEDTAVYYCARQGYDFWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSYDYPLTFGAGTKLELK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QMQLVESGGGVVQPGRSLRLSCAASGFTFSNYAMHWVRQAPGKGLEWVAVIWYDGSNKYYADSVKGRFTISRDNSKNTLYLQMNSLRVEDTAIYYCVRSGYFYDSSGYFDNWGQGTLVTVSS|EIVLTQSPGTLSLSPGERATLSCRASQSVSSYLAWYQQKPGRAPKLLIFGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSTPWTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1250 - 2025-08-15 02:53:35\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVQSGAEVRKPGASVKVSCKASGYTFSSFYTWMHWVKQRPGQGLEWIGWISPYNGVTKYAQKFQGRVTMTADTSISTAYMELSSLRSEDTAVYYCARDSGTTSTPNNLWGQGTLVTVSA|DIVLTQSPAIMSAAPGDKVTMSCSASSSVGYSYMHWYQQKSGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCQQYSSYPLTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASGFTFSYYMSHWVRQAPGKGLEWVAIIWDGSRNFYAASVEGRFTISRDDAKNTLYLQMNSLRAEDTAVYYCAKHGYWGFGTVGMDYWGQGTLVTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDIATYYCQQYDNLPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1300 - 2025-08-15 02:56:59\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGVVQPGRSLRLSCAASGFTFSNYGMHWVRQAPGKGLEWVASISSSGSTYYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARDDYEGSYDYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGRAPKLLIYSASSLYSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYNSTPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGRSLRLSCAASGFTFSNYGMHWVRQTPDKGLEWVASISSYGDYTYADSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCAREDGYFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYDASSLESGVPSRFSGSGSGTDFTLTISSLQPEDIATYYCQQYDNYPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1350 - 2025-08-15 03:00:51\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLQQSGAELMKPGASVKISCRASGYTFTEYWIGWIRQSPGKGLEWIGEIYYEGSTNYNEKFKNKATLTVDKSSTTVYMELSSLTSDDSAVYFCVRDYSADYWGQGTTLTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVSGIDSVSTYYADSVKGRFTISRDNKKNTLYLQMNSLRVEDTAIYYCARSGGYDVWSGDYWGQGTLVTVSA|DIQLTQSPSSLAVSLGERVTMTCKSSQSLLHSNGKAENVAWYQQKPGQPPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVQAEDLAVYYCQQYYRYYPRTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1400 - 2025-08-15 03:04:42\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLQQSGAELMKPGASVKISCKASGYTFTEYMHWVKQRPEQGLEWIGWIDPNSGTNYNEKFKGKATLTADKSSSTAYMDLQLSSLTSEDSAVYYCTRDKGYFDYWGQGTTLTVSS|DIVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGYNYLDWYLQKPGQSPQLLIYLTSNRASGVPDRFTGSGSGTDFTLKISRVEAEDLGVYYCFQGSHVPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVQPGRSLRLSCAASGFSFSSYAMSWVRQAPGKGLEWVSVIPYGGSYTYYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCARVRDTNLGDYWGQGTLVTVSS|EIVMTQSPATLSVSPGERATLSCRASESVSSDLAWYQQKPGQAPRLLIFGASSRATGVPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1450 - 2025-08-15 03:08:17\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFAFSRYWMNWVRQAPGKGLEWIGEILPSGDSTYYADSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARVDRGYWGQGTLVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQGVSNYLNWFQQKPGQSPKLLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGIYYCFQGSHVPYTFGGGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGRSLRLSCAASAFTFSSYAMHWVRQAPGKGLEWVASISSYYGSTSYADSVKGRFTISRDNSKNTLYLQMSSLRAEDTAVYYCARYDWSIFDPWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQYDYYPMFGQGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1500 - 2025-08-15 03:12:08\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLLESGGGLVKPGGSLKLSCAASGFTFSNYAMSWVRQTPEKRLEWVASISGYTYYYSDSVKGRFTISRDNAKSAYLQMSSLRAEDTAVYYCARSTTTGSWSFDYWGQGTLVTVSA|DIVMTQSPDSLAVSLGERATINCKSSQSLLRSNQKNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCHQYNSAWTFGGGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFTFSSYDMSWVRQAPGKGLEWVAYISSSGGSTYYADSVKGRFTISRDDSRASTAYLQMNSLRAEDTAVYYCARGDYFWYQRTPFGESYPWFDPWGQGTLVTVSS|EIVMTQSPATLSLSPGERATLSCRASQSIRDYGGSFSYWYQQKPGQPPKLLIFATSKRSTLGVPARFSGSGSGTDFTLTISSLQAEDVAVYYCQQHYITPRTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1550 - 2025-08-15 03:16:06\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLVKPGGSLKLSCAASGFTFSRYMYWVRPTKGLEWVARIHPDSGETAYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARSAAYYYYDYYYAMDYWGQGTSVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSIKNYLHWLLQRPGQSPKRLIYKASSLESGVPARFSGSGSGTDFTLKISRVEAEDVGVYYCMQGSHWPRTFGQGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQSGPELVKPGASVKMSCKASGYTFTSDWIHWVKQRPGQGLEWIGEILPGSGSTNYNEKFKDKATLTADKSSNTAYMQLSSLTSEDSAVYYCAREGWYGPDYWGQGTTLTVSS|DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSNEDPYTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1600 - 2025-08-15 03:19:42\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLVQSGAEVKKPGASVKVSCKASGYTFTSYGISWVRQAPGQGLEWMGGIIPIFGTANYAQKFQGRVTMTVDTSISTSTAYMELRSEDTAVYYCARLGDYSWGFDIWGQGTLVTVSS|DIVLTQSPASLAVSLGQRATISCRASESVDSFLHWYQQKPGQPPKLLIYKASTRESGVPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWIKQRPGHGLEWIGEILGGGSTNYNEKFKDKATLTADTSSSTAYMQLSSLTSEDSAVYYCARERGDGYFDYWGQGTTLTVSS|DIVMTQTPLSLPVSLGDQASISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYYCFQGSHVPWTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1650 - 2025-08-15 03:23:18\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLLESGGGVVQPGRSLRLSCAASGFTFRDFGMHWVRQAPGKGLEWLAIYWVDSSTFYADSVKGRFTISRDNSKNTLYLQMRAEDTAVYYCARSGFDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQSISTWLAWYQQKPGRAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLQQSGPELVKPGASVKMSCKASGYTFTDYYITWVRQSPGQRLEWMGWINGNGNTKYNEKFKNKATLTVDKSSTTVYMELSSLTSEDTAVYYCATRGEGGRFDIWGQGTMVTVSS|DIQLTQSPSFLSASVGDRVTITCRASKSLRYLGWYQQKPGKAPKLLIYDASNLETGVPSRFSGSRSGTDFTLTISSLQPEDIATYYCQQSYTLSITFGQGTRVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1700 - 2025-08-15 03:26:52\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASAFTFSSYDMSWVRQAPGKGLEWVASISSYYGSTSYADSVKGRFTISRDNSKNTLYLQMRAEDTAIYYCAR   EVVLTQSPGTLSLSPGERATLSCRASQVGNSALNWYLQQKPGQPPRLLIYASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGSSPWTFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: EVQLVESGGGLVKPGGSLRLSCAASGFSFSSYTMSWVRQTPEKRLEWVAYISSGYTYYSDSVKGRFTISRDNAKNTLYLQMRAEDTAIYYCARDCGVYALDYWGQGTLVTVSS|DIVMTQSPLSLSVTIGQPASISCKSSQNLLNNGNQKNYLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSATDFTLTINNVQAEDLADYHCCQHYDNPLTFGGGTKVEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1750 - 2025-08-15 03:30:32\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: QLQLQESGPGLVKPSETLSLTCTVSGGSISNYWSWIRQPPGKGLEWIGSIYYGGSTYYNPSLKSRVTISVDTSKNQFSLKLTAADTAVYYCARHGSLGFDPWGQGTLVTVSS|DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPGQSPQLLIYSASNRYTGVPDRFTGSGSGTDFTLTISSVKAEDLGVYYCMQALQTPWTTFGAGTKLEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: QVQLVESGGGVVQPGRSLRLSCAASGFTFSRYGIHWVRQTPGKGLEWVAVIWFDGSNKYYADSVKGRFTISRDNAKNTLYLQMSSLRAEDTAVYYCAREGYDYDVWGQGTLVTVSS|DIQLTQSPDSLAVSLGERATINCKSSQNNKNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTINSVQAEDLAVYYCQQHYTIPRTFGGGTKLEIK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST GENERATION - PERIODIC - STEP 1800 - 2025-08-15 03:34:12\n",
      "================================================================================\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input: KVFGRCELAAAM<epi>K</epi><epi>R</epi>HGL<epi>D</epi><epi>N</e...\n",
      "Generated: EVQLVESGGGLIQPGGSLRLSCAASGFNISSSIHWVRQAPGKGLEWVASISSSYGYTSYDLSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARSAAYDYWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASSSVSYMHWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISRLEPEDFAVYYCQQYGTYPITFGQGTKVEIK\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Input: NLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFT...\n",
      "Generated: VQLVESGGGLVQPGGSLRLSCAASGFNIKDYYMSWVRQAPGKGLEWVASISSSSGSTSYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCAREGYDYYSPYHNWFDPWGQGTLVTVSS|DIQMTQSPSSLSASVGDRVTITCRASQDISNYLNWYQQKPDGTVKLLIYYTSSLHSGVPSRFSGSRSGTDYTLTISSLQPEDFATYYCQQYKYVPWTFGQGTKVEIK\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Set up SFTTrainer\n",
    "from trl import SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    callbacks=[test_callback],  # Log every 50 steps\n",
    ")\n",
    "\n",
    "## Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Finish wandb run\n",
    "#wandb.finish()\n",
    "\n",
    "## Save the trained model\n",
    "trainer.save_model(training_args.output_dir)\n",
    "print(f\"Model saved to {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cfebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87484d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c239d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ff22ec",
   "metadata": {},
   "source": [
    "### This script is used to clear vram. For testing purposes only and when you want to clear the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdf5eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory before: 30.16 GB allocated\n",
      "GPU Memory reserved: 30.29 GB reserved\n",
      "Previous model cleared from memory\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "# Clear any existing models from GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check current GPU memory usage\n",
    "print(f\"GPU Memory before: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB allocated\")\n",
    "print(f\"GPU Memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB reserved\")\n",
    "# If you have a model loaded, delete it first\n",
    "try:\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Previous model cleared from memory\")\n",
    "except:\n",
    "    print(\"No previous model to clear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
