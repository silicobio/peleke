{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3deb958f",
   "metadata": {},
   "source": [
    "# Fine-Tune an LLM for Antibody Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920184da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810495bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## For Pytorch, see if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3861480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>AntigenChains</th>\n",
       "      <th>HeavySeq</th>\n",
       "      <th>LightSeq</th>\n",
       "      <th>AntigenSeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8xa4</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>A | B</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...</td>\n",
       "      <td>SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9cph</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...</td>\n",
       "      <td>AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...</td>\n",
       "      <td>KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9d7i</td>\n",
       "      <td>J</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9d7o</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...</td>\n",
       "      <td>YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...</td>\n",
       "      <td>LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdb Hchain Lchain AntigenChains  \\\n",
       "4   8xa4      C      D         A | B   \n",
       "9   9cph      H      L             A   \n",
       "10  9d7i      H      G             E   \n",
       "11  9d7i      J      I             C   \n",
       "12  9d7o      H      G             E   \n",
       "\n",
       "                                             HeavySeq  \\\n",
       "4   QLQLQESGPGLVKPSETLSLTCTVSGGSISSNNDYWGWIRQPPGKG...   \n",
       "9   EVQLVESGGGLVQPGGSLRLSCAASGFNLSSSSIHWVRQAPGKGLE...   \n",
       "10  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "11  VQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLEW...   \n",
       "12  QVQLQESGPGVVKSSETLSLTCTVSGGSMGGTYWSWLRLSPGKGLE...   \n",
       "\n",
       "                                             LightSeq  \\\n",
       "4   EIVLTQSPGTLSLSPGERVTLSCRASQRVSSTYLAWYQQKPGQAPR...   \n",
       "9   AQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLL...   \n",
       "10  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "11  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "12  YELTQPPSVSVSPGQTATITCSGASTNVCWYQVKPGQSPEVVIFEN...   \n",
       "\n",
       "                                           AntigenSeq  \n",
       "4   SCNGLYYQGSCYILHSDYKSFEDAKANCAAESSTLPNKSDVLTTWL...  \n",
       "9   KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEK...  \n",
       "10  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...  \n",
       "11  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...  \n",
       "12  LWVTVYYGVPVWKDAETTLFCASDNVWATHACVPTDPNPQEIHLEN...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load dataset\n",
    "df = pd.read_csv(\"../data/sabdab/sabdab_with_sequences.tsv\", sep='\\t')\n",
    "\n",
    "## Remove rows with missing sequences\n",
    "df = df.dropna(subset=['HeavySeq', 'LightSeq', 'AntigenSeq'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989b8e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10073/10073 [00:02<00:00, 4625.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Format prompts\n",
    "def format_prompt(example):\n",
    "    return {\n",
    "        \"text\": f\"Antigen: {example['AntigenSeq']}\\nAntibody: {example['HeavySeq']}|{example['LightSeq']}\\n\"\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(format_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018d2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:30<00:00,  5.11s/it]\n"
     ]
    }
   ],
   "source": [
    "## Load base tokenizer and model\n",
    "model_name = \"microsoft/phi-4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=0, trust_remote_code=True)\n",
    "\n",
    "## Convert model to float32 for training\n",
    "model = model.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd7f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extend tokenizer with special tokens\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "extra_tokens = amino_acids + [\"|\"]# [\"[\", \"]\", \"|\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1fc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100352, 5120, padding_idx=100349)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if tokens already exist in the tokenizer's vocabulary\n",
    "new_tokens = [t for t in extra_tokens if t not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4d6a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10073/10073 [00:10<00:00, 989.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Tokenize the dataset\n",
    "def tokenize(example):\n",
    "    # return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    encoded = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "    # encoded[\"labels\"] = encoded[\"input_ids\"]#.copy()\n",
    "    return encoded\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n",
    "\n",
    "## Remove unnecessary columns from the tokenized dataset\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\n",
    "    'pdb', 'Hchain', 'Lchain', 'AntigenSeq', 'AntigenChains',\n",
    "    'HeavySeq', 'LightSeq', '__index_level_0__', 'text'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41b282e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 8058\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split the dataset into train and validation sets\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=1337)\n",
    "\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fccca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/peleke-{model_name.split('/')[-1]}\",\n",
    "    ## Batching\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    ## Epochs and warmups\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=100,\n",
    "    ## Optimization\n",
    "    weight_decay=0.01,\n",
    "    ## Logging and saving\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    # fp16=True,\n",
    "    gradient_checkpointing=True, ## If having memory issues\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aab7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PEFT configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    # target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "    target_modules=[\"o_proj\", \"qkv_proj\"],\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abc5debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  ## Important: MLM=False for causal LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b96dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colby\\AppData\\Local\\Temp\\ipykernel_47500\\2332457157.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "## Trainer\n",
    "trainer = Trainer(\n",
    "    # model=model,\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedae7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='12087' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/12087 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fine-tune\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
